{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU_Najwachille.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NajwaMoursli/HPCA_Project/blob/main/GPU_Najwachille.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJCh1yt7VK5I"
      },
      "source": [
        "# HPCA Project : Batch Merge and Merge Sort Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVfLGNytVNJO",
        "outputId": "b1200e00-b75d-4eb0-fc00-81bb5c5791fa"
      },
      "source": [
        "# Preparation\n",
        "!nvcc --version\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "!mkdir -p src/repos src/obj\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-0cg9ph_h\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-0cg9ph_h\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=a592ddbc63cd9e7835d29133a1ccf8a177bc5dccef86addd29fe6ce9e3a61844\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jgwjhqn2/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ6qsBgAN35x",
        "outputId": "19c930d2-13d0-4dda-db65-51d55e822131"
      },
      "source": [
        "# Type de carte graphique. Mieux avec Tesla T4 ou T plus élevé\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec 15 14:40:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjHKwNmYxD4_",
        "outputId": "a339ea8e-6aa3-4a62-98a9-e218ac00fd56"
      },
      "source": [
        "!cd src  && rm -Rf Makefile && wget -P . https://gist.github.com/NajwaMoursli/f1b95b7d8ceb8d1abb8c446ece66960e/raw/Makefile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-15 14:40:19--  https://gist.github.com/NajwaMoursli/f1b95b7d8ceb8d1abb8c446ece66960e/raw/Makefile\n",
            "Resolving gist.github.com (gist.github.com)... 13.114.40.48\n",
            "Connecting to gist.github.com (gist.github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://gist.githubusercontent.com/NajwaMoursli/f1b95b7d8ceb8d1abb8c446ece66960e/raw/Makefile [following]\n",
            "--2020-12-15 14:40:20--  https://gist.githubusercontent.com/NajwaMoursli/f1b95b7d8ceb8d1abb8c446ece66960e/raw/Makefile\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 712 [text/plain]\n",
            "Saving to: ‘./Makefile’\n",
            "\n",
            "Makefile            100%[===================>]     712  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-15 14:40:20 (33.8 MB/s) - ‘./Makefile’ saved [712/712]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A-3FealxmSv",
        "outputId": "085368a6-2dc2-4049-9741-e2b54c5bc226"
      },
      "source": [
        "!rm -Rf src/repos/functions\n",
        "!git clone https://gist.github.com/NajwaMoursli/5fe67ed5c22e84ba7a6331fcf4c79249 src/repos/functions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'src/repos/functions'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 12\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFLE4snL29OV",
        "outputId": "7f7b715b-228e-4d48-d6aa-581b02e7cb2f"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF-8m_Wh39Qp",
        "outputId": "e97618aa-1faf-4500-9bae-e5f36ad66261"
      },
      "source": [
        "!hostname"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "579a74ff6ecf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGNzuajVcM9g"
      },
      "source": [
        "# Question 1.1 : Algo Merge Path of the Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5JjY_oYLiMJU",
        "outputId": "314e12e4-053e-43d5-ef53-0b8c283db731"
      },
      "source": [
        "%%%%cuda --name main.cu\n",
        "/* To parallelize the algorithm, the grid has to be extended to the maximum size\n",
        "equalt to max(|A|,|B|)x max(|A|,|B|). We note K_0 and P_0 respectively the\n",
        "low point and the high point of the ascending diagonals Delta_k.\n",
        "On GPU, each thread k in [[0,|A|+|B|-1]] is responsible of ONE diagonal.\n",
        "It finds the intersection of the merge path and the diagonal Delta_k with a\n",
        "binary search described in Algorithm 2.\n",
        "(1) For |A| + |B| <= 1024 write a kernel \"mergeSmall_k\" that merges A and B\n",
        "using only one block of threads\n",
        "*/\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<algorithm>\n",
        "#include<fstream> //to export data\n",
        "#include<time.h> //random numbers\n",
        "#include \"repos/functions/functions.hpp\"\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "\n",
        "//####################### KERNEL #################################\n",
        "__global__ void mergeSmall_k(int *A, int dim_A, int *B, int dim_B, int *M){\n",
        "  int idx = threadIdx.x;//thread index \n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "  if(idx < (dim_A + dim_B)){\n",
        "    if(idx>dim_A){\n",
        "      K_x = idx - dim_A; //(K_x, K_y): low point of diagonal\n",
        "      K_y = dim_A;\n",
        "      P_x = dim_A; //(P_x,P_y): high point of diagonal\n",
        "      P_y = idx - dim_A;\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = idx;\n",
        "      P_x = idx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2); //integer\n",
        "      //distance on y == distance on x, because diagonal\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      //offset is an \"int\" (integer), so it's rounded to the smaller integer -> Q will be closer to K\n",
        "      if (Q_y>=0 && Q_x<=dim_B && (Q_y == dim_A || Q_x==0 || A[Q_y] > B[Q_x-1]) ){\n",
        "        // (Q_y>=0 and Q_x<=B) -> Q is in the grid\n",
        "        // Q_y=|A| -> Q is on the down border\n",
        "        // Q_x=0   -> Q is on the left border\n",
        "        // A[Q_y>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if (Q_x == dim_B || Q_y == 0 || A[Q_y-1] <= B[Q_x]){\n",
        "            // Q_x=|B| -> Q is on the right border\n",
        "            // Q_y=0   -> Q in on the up border\n",
        "            // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q'\n",
        "              if (Q_y<dim_A && (Q_x == dim_B || A[Q_y]<= B[Q_x]) )\n",
        "              //if Q is not on the down border (= if the \"path\" can go down) and it MUST go down\n",
        "                M[idx] = A[Q_y]; //the \"path\" goes down\n",
        "              else //if it can't go down\n",
        "                M[idx] = B[Q_x]; //the \"path\" goes right (in B direction)\n",
        "\n",
        "              break;\n",
        "          }else{ //if the path is over Q but not under Q\n",
        "              K_x = Q_x + 1; //move Q up by moving K up (updating Q_x to remain on diagonal)\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{ //if the path is under Q\n",
        "        P_x = Q_x - 1; //move Q down by moving P down (updating Q_x to remain on diagonal)\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "//########################### WRAPPER ###################################\n",
        "void wrapper_mergeSmall(int *A, int dim_A, int *B, int dim_B, int *M, float & duration){\n",
        "  int *A_GPU, *B_GPU, *M_GPU;\n",
        "\n",
        "  //Initializating the timer:\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  //Initialization on GPU:\n",
        "  testCUDA(cudaMalloc(&A_GPU, dim_A*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&B_GPU, dim_B*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&M_GPU, (dim_A+dim_B)*sizeof(int)));\n",
        "\n",
        "  testCUDA(cudaMemcpy(A_GPU, A, dim_A*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(B_GPU, B, dim_B*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  //Launching the operation on the GPU\n",
        "  mergeSmall_k<<<1,1024>>>(A_GPU, dim_A, B_GPU, dim_B, M_GPU);\n",
        "\n",
        "  //Bringing back the results from GPU to CPU:\n",
        "  testCUDA(cudaMemcpy(M, M_GPU, (dim_A+dim_B)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  //Stop the timer:\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  printf(\"Execution time: %f ms\\n\", TimerV);\n",
        "  duration = TimerV;\n",
        "\n",
        "  //Freeing the GPU MEMORY\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "//############################# MAIN ###################################\n",
        "int main(){\n",
        "  //Initialization:\n",
        "  int *A, *B, *M;\n",
        "  int d[10];\n",
        "  float duration[10];\n",
        "  for(int i=0; i<10; ++i)\n",
        "    d[i] = pow(2,i+1); //2, 4, 8, ..., 1024\n",
        "\n",
        "  for(int k=0; k<10; k++){\n",
        "    srand (time(NULL));\n",
        "    int dim_A = rand() % (d[k]-1) + 1; //choosing randomly the dimension\n",
        "    int dim_B = d[k] - dim_A;\n",
        "    if(dim_B > dim_A) //necessary condition: |A| > |B|\n",
        "      std::swap(dim_A,dim_B);\n",
        "    A = (int*)malloc(dim_A*sizeof(int));\n",
        "    B = (int*)malloc(dim_B*sizeof(int));\n",
        "    generate_random(A,dim_A,0,1000); //random generation of the input arrays\n",
        "    A[dim_A/2] = 1000;\n",
        "    mergesort(A,0,dim_A-1);\n",
        "    generate_random(B,dim_B,0,1000);\n",
        "    B[dim_B/2] = -1;\n",
        "    mergesort(B,0,dim_B-1);\n",
        "    M = (int*)malloc((dim_A+dim_B)*sizeof(int));\n",
        "\n",
        "    printf(\"%i) \\nA : \\n\",k);\n",
        "    print_array(A,dim_A);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"B: \\n\");\n",
        "    print_array(B,dim_B);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    //###### WRAPPER CALL ######\n",
        "    wrapper_mergeSmall(A, dim_A, B, dim_B, M, duration[k]);\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    printf(\"M: \\n\");\n",
        "    print_array(M, dim_A+dim_B);\n",
        "    printf(\"\\n \\n \\n\");\n",
        "\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(M);\n",
        "  }\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Z59G4Ky_rD",
        "outputId": "327c0ff6-cf29-4859-a7e0-f735e211394c"
      },
      "source": [
        "!cd src && make "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(23): warning: variable \"P_x\" was set but never used\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7rjT2gD4Re6",
        "outputId": "82d29f7a-a83f-4f52-e517-e0ac312ff2e2"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "0) \n",
            "A : \n",
            "dim: 1 \n",
            "1000 \n",
            "\n",
            "B: \n",
            "dim: 1 \n",
            "-1 \n",
            "\n",
            "Execution time: 0.264512 ms\n",
            "\n",
            "M: \n",
            "dim: 2 \n",
            "-1 1000 \n",
            "\n",
            " \n",
            " \n",
            "1) \n",
            "A : \n",
            "dim: 2 \n",
            "488 1000 \n",
            "\n",
            "B: \n",
            "dim: 2 \n",
            "-1 922 \n",
            "\n",
            "Execution time: 0.149248 ms\n",
            "\n",
            "M: \n",
            "dim: 4 \n",
            "-1 488 922 1000 \n",
            "\n",
            " \n",
            " \n",
            "2) \n",
            "A : \n",
            "dim: 5 \n",
            "206 234 488 894 1000 \n",
            "\n",
            "B: \n",
            "dim: 3 \n",
            "-1 333 910 \n",
            "\n",
            "Execution time: 0.155264 ms\n",
            "\n",
            "M: \n",
            "dim: 8 \n",
            "-1 206 234 333 488 894 910 1000 \n",
            "\n",
            " \n",
            " \n",
            "3) \n",
            "A : \n",
            "dim: 11 \n",
            "79 149 206 234 361 378 488 894 910 922 1000 \n",
            "\n",
            "B: \n",
            "dim: 5 \n",
            "-1 300 351 377 933 \n",
            "\n",
            "Execution time: 0.135168 ms\n",
            "\n",
            "M: \n",
            "dim: 16 \n",
            "-1 79 149 206 234 300 351 361 377 378 488 894 910 922 933 1000 \n",
            "\n",
            " \n",
            " \n",
            "4) \n",
            "A : \n",
            "dim: 19 \n",
            "149 206 234 300 333 351 361 377 378 488 488 500 624 771 894 910 922 933 1000 \n",
            "\n",
            "B: \n",
            "dim: 13 \n",
            "-1 0 302 474 562 595 709 723 751 755 812 832 919 \n",
            "\n",
            "Execution time: 0.131968 ms\n",
            "\n",
            "M: \n",
            "dim: 32 \n",
            "-1 0 149 206 234 300 302 333 351 361  ... 755 771 812 832 894 910 919 922 933 1000 \n",
            "\n",
            " \n",
            " \n",
            "5) \n",
            "A : \n",
            "dim: 47 \n",
            "0 79 149 153 206 234 296 300 302 321  ... 894 907 910 919 922 922 933 954 987 1000 \n",
            "\n",
            "B: \n",
            "dim: 17 \n",
            "-1 201 269 331 375 391 524 543 565 803 822 849 883 929 954 967 979 \n",
            "\n",
            "Execution time: 0.147968 ms\n",
            "\n",
            "M: \n",
            "dim: 64 \n",
            "-1 0 79 149 153 201 206 234 269 296  ... 922 922 929 933 954 954 967 979 987 1000 \n",
            "\n",
            " \n",
            " \n",
            "6) \n",
            "A : \n",
            "dim: 101 \n",
            "0 79 83 94 98 124 149 153 172 201  ... 922 929 933 954 954 967 979 987 991 1000 \n",
            "\n",
            "B: \n",
            "dim: 27 \n",
            "-1 6 172 201 269 295 340 349 369 403  ... 790 809 829 843 906 922 943 947 967 992 \n",
            "\n",
            "Execution time: 0.147456 ms\n",
            "\n",
            "M: \n",
            "dim: 128 \n",
            "-1 0 6 79 83 94 98 124 149 153  ... 947 954 954 967 967 979 987 991 992 1000 \n",
            "\n",
            " \n",
            " \n",
            "7) \n",
            "A : \n",
            "dim: 176 \n",
            "0 6 10 13 44 51 77 79 83 94  ... 954 954 967 967 977 979 987 991 992 1000 \n",
            "\n",
            "B: \n",
            "dim: 80 \n",
            "-1 60 63 86 97 110 112 116 130 136  ... 893 901 905 931 952 971 980 981 989 994 \n",
            "\n",
            "Execution time: 0.149056 ms\n",
            "\n",
            "M: \n",
            "dim: 256 \n",
            "-1 0 6 10 13 44 51 60 63 77  ... 977 979 980 981 987 989 991 992 994 1000 \n",
            "\n",
            " \n",
            " \n",
            "8) \n",
            "A : \n",
            "dim: 360 \n",
            "0 0 6 10 10 13 23 28 31 41  ... 979 980 981 987 987 989 991 992 994 1000 \n",
            "\n",
            "B: \n",
            "dim: 152 \n",
            "-1 8 10 15 16 27 40 41 41 41  ... 939 944 946 947 950 952 956 960 969 986 \n",
            "\n",
            "Execution time: 0.153984 ms\n",
            "\n",
            "M: \n",
            "dim: 512 \n",
            "-1 0 0 6 8 10 10 10 13 15  ... 980 981 986 987 987 989 991 992 994 1000 \n",
            "\n",
            " \n",
            " \n",
            "9) \n",
            "A : \n",
            "dim: 881 \n",
            "0 0 3 6 6 6 8 8 10 10  ... 986 987 987 989 991 992 992 994 997 1000 \n",
            "\n",
            "B: \n",
            "dim: 143 \n",
            "-1 12 16 18 30 32 40 56 65 65  ... 924 940 941 946 968 975 980 985 991 993 \n",
            "\n",
            "Execution time: 0.152096 ms\n",
            "\n",
            "M: \n",
            "dim: 1024 \n",
            "-1 0 0 3 6 6 6 8 8 10  ... 987 989 991 991 992 992 993 994 997 1000 \n",
            "\n",
            " \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyYEr-bTcAyO"
      },
      "source": [
        "# Question 1.2 : Upgrade Algo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "biNVSxpqWvkF",
        "outputId": "48407cf0-4fea-4007-a3f9-a333222e6d4c"
      },
      "source": [
        "%%cuda --name main.cu\n",
        "/* For any size |A| + |B| = d sufficiently smaller than the global memory, write\n",
        "TWO kernels that merge A and B using various blocks.\n",
        "The first kernel \"pathBig_k\" finds the merge path and\n",
        "the second one \"mergeBig_k\" merges A and B. */\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include<fstream> //to export data\n",
        "#include<algorithm>\n",
        "#include \"repos/functions/functions.hpp\"\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "#define NSM 4096 // 4096 optimal for execution time\n",
        "//56 = number of multiprocessors (SM) -> prop.multiProcessorCount\n",
        "#define Z 32 //Number of thread per block\n",
        "\n",
        "//#################### KERNEL - find MERGE PATH in the PARTITION POINTS ##############################\n",
        "//X_path -> horizontal (>) <-> \"B\"-direction\n",
        "//Y_path -> vertical (v) <-> \"A\"-direction\n",
        "__global__ void MergePath_partition(int *A_gpu, int dim_A, int *B_gpu, int dim_B, int *X_gpu, int *Y_gpu){\n",
        "//Divide the work among the processors: PARTITIONING\n",
        "//\"idx\" is the partition index: it goes from 0 to #partitions (=#NSM)\n",
        "  int idx = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A+dim_B);// dim(M)=[(dim_A+dim_B)/NSM, ....,(dim_A+dim_B)]\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "  //Cross diagonal binary search for MERGE PATH at the PARTITION POINTS on GLOBAL MEMORY\n",
        "  //Writing the MERGE PATH at PARTITION POINTS on the GLOBAL MEMORY\n",
        "    if(idx>dim_A){\n",
        "      K_x = idx - dim_A; //(K_x, K_y): low point of diagonal\n",
        "      K_y = dim_A;\n",
        "      P_x = dim_A;      //(P_x,P_y): high point of diagonal\n",
        "      P_y = idx - dim_A;\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = idx;\n",
        "      P_x = idx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if (Q_y>=0 && Q_x<=dim_B && (Q_y == dim_A || Q_x==0 || A_gpu[Q_y] > B_gpu[Q_x-1]) ){\n",
        "      // A[Q_y]>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if (Q_x == dim_B || Q_y == 0 || A_gpu[Q_y-1] <= B_gpu[Q_x]){\n",
        "          // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q' -> Q is on the \"path\"\n",
        "                X_gpu[idx] = Q_x;\n",
        "                Y_gpu[idx] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  //The Merge Path terminates in the point (dim_B, dim_A):s\n",
        "  if(blockIdx.x==0 && threadIdx.x==0){\n",
        "    X_gpu[dim_A+dim_B] = dim_B;\n",
        "    Y_gpu[dim_A+dim_B] = dim_A;\n",
        "  }\n",
        "}\n",
        "// threadIdx.x => thread’s index within a block \n",
        "// block Idx.x => the current block’s index within the grid \n",
        "\n",
        "//######################### KERNEL - BIG PATH #################################\n",
        "__global__ void pathBig_k(int *X_gpu, int *Y_gpu, const int *A_gpu, const int *B_gpu, int dim_A, int dim_B){\n",
        "  //idx_start, idx_end: beginning of the partition, end of the partition\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  //x_start, y_start: coordinates of the first element of the MergePath in the partition\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  //Place Z elements from each input array in the SHARED MEMORY for each partition \n",
        "  // Z = 32 threads in a block using the local shared memory of the SM\n",
        "  __shared__ int A_sh[Z], B_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "//Cross diagonal binary search for MERGE PATH on SHARED MEMORY\n",
        "//Writing the MERGE PATH on the GLOBAL MEMORY\n",
        " while(idx_start + idx_sh <= idx_end && idx_sh < Z){\n",
        "   //Placing the input arrays in the SHARED MEMORY\n",
        "  if(idx_sh + y_start < dim_A) //in order to have valid indexes for \"A_sh\" and \"A_gpu\"\n",
        "    A_sh[idx_sh] = A_gpu[idx_sh + y_start];\n",
        "  if(idx_sh + x_start< dim_B)\n",
        "    B_sh[idx_sh] = B_gpu[idx_sh + x_start];\n",
        "\n",
        "    if(idx_sh + y_start + 1 > dim_A){\n",
        "      //since we know already the Merge Path at the starting point: (x_start, y_start)\n",
        "      //we want to look for the Merge Path from the \"next diagonal\", that's why \"+1\"\n",
        "      K_x = x_start + (idx_sh + y_start + 1 - dim_A);\n",
        "      K_y = dim_A;\n",
        "      } else{\n",
        "        K_x = x_start;\n",
        "        K_y = idx_sh + y_start + 1;\n",
        "        }\n",
        "    if(idx_sh + x_start + 1 > dim_B){\n",
        "      P_x = dim_B;\n",
        "      P_y = y_start + (idx_sh + x_start + 1 - dim_B);\n",
        "      } else{\n",
        "        P_x = idx_sh + x_start + 1;\n",
        "        P_y = y_start;\n",
        "      }\n",
        "\n",
        "      while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);// divided into 2 pairs of values (n=abs(K_y-P_y)), and sort them with a kernel function using n/2 blocks\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if ((Q_y>=y_start && Q_y>=0) && (Q_x<=(Z+x_start)<=dim_B) && ((Q_y == (Z+y_start) || Q_y == dim_A) || (Q_x==x_start || Q_x==0) || A_sh[Q_y - y_start] > B_sh[Q_x -1 - x_start]) ){\n",
        "      // A[Q_y>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if ((Q_x == (Z+x_start) || Q_x == dim_B) || (Q_y == y_start || Q_y == 0) || A_sh[Q_y -1 - y_start] <= B_sh[Q_x - x_start]){\n",
        "                X_gpu[idx_start + idx_sh +1] = Q_x;\n",
        "                Y_gpu[idx_start + idx_sh +1] = Q_y;\n",
        "\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    //Updating the indexes\n",
        "    x_start = X_gpu[idx_start + Z]; //x_start = x_end\n",
        "    y_start = Y_gpu[idx_start + Z]; //y_start = y_end\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "\n",
        "//######################### KERNEL to MERGE  ##################################\n",
        "__global__ void mergeBig_k(int *X_gpu, int *Y_gpu, int *A_gpu, int *B_gpu, int *M_gpu, int dim_A, int dim_B){\n",
        "\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  //Place Z ponits of the MERGE PATH in the SHARED MEMORY\n",
        "  __shared__ int X_sh[Z], Y_sh[Z];\n",
        "\n",
        "  int idx_sh = threadIdx.x;// threadIdx.x => thread’s index within a block \n",
        "\n",
        "\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "   //Placing the MERGE PATH in the SHARED MEMORY\n",
        "    X_sh[idx_sh] = X_gpu[idx_start + idx_sh + 1];\n",
        "    Y_sh[idx_sh] = Y_gpu[idx_start + idx_sh + 1];\n",
        "\n",
        "    if(idx_sh == 0 && X_sh[0] > x_start) //If the path is moving right\n",
        "      M_gpu[idx_start] = B_gpu[x_start];\n",
        "    else if(idx_sh ==0) //if the path is moving down\n",
        "      M_gpu[idx_start] = A_gpu[y_start];\n",
        "\n",
        "    if( idx_sh>0 && X_sh[idx_sh]>X_sh[idx_sh-1]) //If the path is moving right\n",
        "      M_gpu[idx_start + idx_sh] = B_gpu[X_sh[idx_sh -1]];\n",
        "    else if(idx_sh > 0) //if the path is moving down\n",
        "      M_gpu[idx_start + idx_sh] = A_gpu[Y_sh[idx_sh -1]];\n",
        "\n",
        "    //Update the indexes\n",
        "    x_start = X_sh[Z-1];\n",
        "    y_start = Y_sh[Z-1];\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "//########################### WRAPPER FIND PATH ###################################\n",
        "//thread are executed within thiq group => wrap (contains 32  threads)\n",
        "void wrapper_MergeSort(int *a, int dim_A, int *b, int dim_B, int *m){\n",
        "  int *A_GPU, *B_GPU, *M_GPU, *X_GPU, *Y_GPU;\n",
        "\n",
        "  int count;\n",
        "  cudaDeviceProp prop;\n",
        "  testCUDA(cudaGetDeviceCount(&count));\n",
        "  testCUDA(cudaGetDeviceProperties(&prop, count-1));\n",
        "  printf(\"\\nGlobal memory size in octet (bytes): %ld \\n\", prop.totalGlobalMem); //ld: long double\n",
        "  printf(\"Max dimension of the two input arrays: %ld \\n\", prop.totalGlobalMem/(sizeof(int)*8)); \n",
        "  printf(\"Shared memory size per block: %ld \\n\", prop.sharedMemPerBlock);\n",
        "  printf(\"Max dimension of the int array in the shared memory: %ld \\n\", prop.sharedMemPerBlock/(sizeof(int)*8)); \n",
        "  printf(\"Number of multiprocessors: %i \\n\", prop.multiProcessorCount); //NSM\n",
        "  printf(\"Maximum number of thread per block: %li \\n\", prop.maxThreadsPerBlock);\n",
        "\n",
        "  //Initilizating the timer:\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  //Initialization on GPU:\n",
        "  testCUDA(cudaMalloc(&A_GPU, dim_A*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&B_GPU, dim_B*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&X_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&Y_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&M_GPU, (dim_A+dim_B)*sizeof(int)));\n",
        "  //Copying the values form one ProcUni to the other ProcUnit\n",
        "  testCUDA(cudaMemcpy(A_GPU, a, dim_A*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(B_GPU, b, dim_B*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  printf(\"Max number of blocks available: %li \\n\",prop.maxGridSize[0] );\n",
        "\n",
        "  printf(\"Number of blocks used: %i \\n\", NSM);\n",
        "  printf(\"Number of thread per block: %i \\n\", Z);\n",
        "\n",
        "\n",
        "  //##### KERNEL CALLS ######\n",
        "  MergePath_partition<<<NSM,1>>>(A_GPU, dim_A, B_GPU, dim_B, X_GPU, Y_GPU);\n",
        "\n",
        "  pathBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, dim_A, dim_B);\n",
        "\n",
        "  mergeBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, M_GPU, dim_A, dim_B);\n",
        "\n",
        "  //Bringing back the results from GPU to CPU:\n",
        "  testCUDA(cudaMemcpy(m, M_GPU, (dim_A+dim_B)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  //Stop the timer:\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  printf(\"Execution time of FIND PATH: %f ms\\n \\n\", TimerV);\n",
        "\n",
        "  //Freeing the GPU MEMORY\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(X_GPU));\n",
        "  testCUDA(cudaFree(Y_GPU));\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "\n",
        "//############################# MAIN ###################################\n",
        "int main(){\n",
        "  //##### INITIALIZATION ######\n",
        "  int *A, *B, *M;\n",
        "  int d = 1000000;\n",
        "  srand (time(NULL));\n",
        "  int dim_A = rand() % d;\n",
        "  int dim_B = d - dim_A;\n",
        "  if(dim_B > dim_A)\n",
        "    std::swap(dim_A,dim_B);\n",
        "  A = (int*)malloc(dim_A*sizeof(int));\n",
        "  B = (int*)malloc(dim_B*sizeof(int));\n",
        "\n",
        "  generate_random(A,dim_A,0,1000);\n",
        "  A[dim_A/2]=-1;//To check if it is sorted correctly\n",
        "  mergesort(A,0,dim_A-1);\n",
        "  generate_random(B,dim_B,0,1000);\n",
        "  B[dim_B/2] = 1000; //To check if it is sorted correctly\n",
        "  mergesort(B,0,dim_B-1);\n",
        "  M = (int*)malloc((dim_A+dim_B)*sizeof(int));\n",
        "\n",
        "  printf(\"A: \\n\");\n",
        "  print_array(A,dim_A);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  printf(\"B: \\n\");\n",
        "  print_array(B,dim_B);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "//##### WRAPPER CALL #####\n",
        "  wrapper_MergeSort(A, dim_A, B, dim_B, M);\n",
        "\n",
        "\n",
        "  printf(\"M: \\n\");\n",
        "  print_array(M, dim_A+dim_B);\n",
        "  printf(\"\\n \\n\");\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(M);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvOYr1fuYeel",
        "outputId": "f64eaa01-d7c4-4185-9e22-bc1de965449b"
      },
      "source": [
        "!cd src && make "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(26): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "main.cu(84): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "\u001b[01m\u001b[Kmain.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid wrapper_MergeSort(int*, int, int*, int, int*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmain.cu:190:77:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Maximum number of thread per block: %li \\n\"\u001b[32m\u001b[K, prop.maxThreadsPerBlo\u001b[m\u001b[K\u001b[01;35m\u001b[Kc\u001b[m\u001b[Kk);\n",
            "                                                      \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cu:209:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Max number of blocks available: %li \\n\"\u001b[32m\u001b[K,prop.maxGridSize[0] \u001b[m\u001b[K\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                  \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-zx_i_IYpkP",
        "outputId": "7cfb1344-3580-48f8-8e9f-e57a7e5fe38d"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "A: \n",
            "dim: 541814 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 999 \n",
            "\n",
            "B: \n",
            "dim: 458186 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "\n",
            "Global memory size in octet (bytes): 17071734784 \n",
            "Max dimension of the two input arrays: 533491712 \n",
            "Shared memory size per block: 49152 \n",
            "Max dimension of the int array in the shared memory: 1536 \n",
            "Number of multiprocessors: 56 \n",
            "Maximum number of thread per block: 1024 \n",
            "Max number of blocks available: 2147483647 \n",
            "Number of blocks used: 4096 \n",
            "Number of thread per block: 32 \n",
            "Execution time of FIND PATH: 4.397280 ms\n",
            " \n",
            "M: \n",
            "dim: 1000000 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EJxYrD8fXJG"
      },
      "source": [
        "# Representation of the merge path 1.2 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r-lw1sm_cZKi",
        "outputId": "c167fccc-5855-4a27-da1e-72cdf69b092b"
      },
      "source": [
        "%%cuda --name main.cu \n",
        "/*The only way to use the shared memory if we want to work with several blocks.\n",
        " Otherwise, we would index the shared thread with the global one \n",
        "- first  kernel (pathBig_k) built the merge path on the global memory \n",
        "- second kernel (mergeBig_k) based on the previous path built to do the merge\n",
        " in the shared memory. */\n",
        "\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include<algorithm>\n",
        "#include\"repos/functions/functions.hpp\"\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "#define NSM 4096 //optimal for execution time -> graph\n",
        "// 56 = number of multiprocessors -> prop.multiProcessorCount\n",
        "#define Z 32\n",
        "\n",
        "//#################### KERNEL - find MERGE PATH in the PARTITION POINTS ##############################\n",
        "//X_path -> horizontal (>) <-> \"B\"-direction\n",
        "//Y_path -> vertical (v) <-> \"A\"-direction\n",
        " __global__ void MergePath_partition(int *A_gpu, int dim_A, int *B_gpu, int dim_B, int *X_gpu, int *Y_gpu){\n",
        "//Divide the work: PARTITIONING\n",
        "//\"idx\" is the partition index: it goes from 0 to #partitions (=#SPs)\n",
        "  int idx = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A+dim_B);\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "    if(idx>dim_A){\n",
        "      K_x = idx - dim_A; //(K_x, K_y): low point of diagonal\n",
        "      K_y = dim_A;\n",
        "      P_x = dim_A;      //(P_x,P_y): high point of diagonal\n",
        "      P_y = idx - dim_A;\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = idx;\n",
        "      P_x = idx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);// integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if (Q_y>=0 && Q_x<=dim_B && (Q_y == dim_A || Q_x==0 || A_gpu[Q_y] > B_gpu[Q_x-1]) ){\n",
        "      // A[Q_y]>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if (Q_x == dim_B || Q_y == 0 || A_gpu[Q_y-1] <= B_gpu[Q_x]){\n",
        "          // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q' -> Q is on the \"path\"\n",
        "                X_gpu[idx] = Q_x;\n",
        "                Y_gpu[idx] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  if(blockIdx.x==0 && threadIdx.x==0){\n",
        "    X_gpu[dim_A+dim_B] = dim_B;\n",
        "    Y_gpu[dim_A+dim_B] = dim_A;\n",
        "  }\n",
        "}\n",
        "\n",
        "//######################### KERNEL - BIG PATH #################################\n",
        "__global__ void pathBig_k(int *X_gpu, int *Y_gpu, const int *A_gpu, const int *B_gpu, int dim_A, int dim_B){\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  __shared__ int X_sh[Z], Y_sh[Z];//shared memory\n",
        "  __shared__ int A_sh[Z], B_sh[Z];//shared memory\n",
        "  int idx_sh = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        " while(idx_start + idx_sh <= idx_end){\n",
        "  if(idx_sh + y_start < dim_A )\n",
        "    A_sh[idx_sh] = A_gpu[idx_sh + y_start];\n",
        "  if(idx_sh + x_start< dim_B)\n",
        "    B_sh[idx_sh] = B_gpu[idx_sh + x_start];\n",
        "     __syncthreads();\n",
        "    if(idx_sh + y_start + 1 > dim_A){\n",
        "      K_x = x_start + (idx_sh + y_start + 1 - dim_A);\n",
        "      K_y = dim_A;\n",
        "      } else{\n",
        "        K_x = x_start;\n",
        "        K_y = idx_sh + y_start + 1;\n",
        "        }\n",
        "    if(idx_sh + x_start + 1 > dim_B){\n",
        "      P_x = dim_B;\n",
        "      P_y = y_start + (idx_sh + x_start + 1 - dim_B);\n",
        "      } else{\n",
        "        P_x = idx_sh + x_start + 1;\n",
        "        P_y = y_start;\n",
        "      }\n",
        "\n",
        "      while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);//integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if ((Q_y>=y_start && Q_y>=0) && (Q_x<=(Z+x_start)<=dim_B) && ((Q_y == (Z+y_start) || Q_y == dim_A) || (Q_x==x_start || Q_x==0) || A_sh[Q_y - y_start] > B_sh[Q_x -1 - x_start]) ){\n",
        "          __syncthreads();\n",
        "      // A[Q_y>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if ((Q_x == (Z+x_start) || Q_x == dim_B) || (Q_y == y_start || Q_y == 0) || A_sh[Q_y -1 - y_start] <= B_sh[Q_x - x_start]){\n",
        "              __syncthreads();\n",
        "          // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q' -> Q is on the \"path\"\n",
        "                  X_sh[idx_sh] = Q_x;\n",
        "                  Y_sh[idx_sh] = Q_y;\n",
        "                  //X_gpu[idx_start + idx_sh +1] = Q_x;\n",
        "                  //Y_gpu[idx_start + idx_sh +1] = Q_y;\n",
        "                 __syncthreads();\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "    //x_start = X_gpu[idx_start + Z];\n",
        "    //y_start = Y_gpu[idx_start + Z];\n",
        "     x_start = X_sh[Z-1];\n",
        "     y_start = Y_sh[Z-1];\n",
        "     X_gpu[idx_start + idx_sh +1] = X_sh[idx_sh];\n",
        "     Y_gpu[idx_start + idx_sh +1] = Y_sh[idx_sh];\n",
        "      __syncthreads();\n",
        "    idx_start += Z; //update index !!!\n",
        "  }\n",
        "}\n",
        "\n",
        "//######################### KERNEL to MERGE  ##################################\n",
        "__global__ void mergeBig_k(int *X_gpu, int *Y_gpu, int *A_gpu, int *B_gpu, int *M_gpu, int dim_A, int dim_B){\n",
        "\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  __shared__ int X_sh[Z], Y_sh[Z];\n",
        "  __shared__ int A_sh[Z], B_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "\n",
        " while(idx_start + idx_sh < idx_end){ \n",
        "   if(idx_sh < Z-1 && idx_sh + y_start < dim_A){\n",
        "     A_sh[idx_sh] = A_gpu[idx_sh + y_start];\n",
        "   }\n",
        "  if(idx_sh < Z-1 && idx_sh + x_start<= dim_B){\n",
        "     B_sh[idx_sh] = B_gpu[idx_sh + x_start];\n",
        "   }\n",
        "    X_sh[idx_sh] = X_gpu[idx_start + idx_sh + 1];\n",
        "    Y_sh[idx_sh] = Y_gpu[idx_start + idx_sh + 1];\n",
        "    printf(\"X[%i] = %i, Y[%i] = %i\", idx_sh, X_sh[idx_sh], idx_sh,Y_sh[idx_sh]);\n",
        "    __syncthreads();\n",
        "    if(idx_sh == 0 && X_sh[0] > x_start)\n",
        "      M_gpu[idx_start] = B_gpu[x_start];\n",
        "    else if(idx_sh ==0)\n",
        "      M_gpu[idx_start] = A_gpu[y_start];\n",
        "\n",
        "    if( idx_sh>0 && X_sh[idx_sh]>X_sh[idx_sh-1])\n",
        "       // M_gpu[idx_start + idx_sh] = B_gpu[X_sh[idx_sh -1]];\n",
        "        M_gpu[idx_start + idx_sh -1] = B_gpu[X_sh[idx_sh-1]];\n",
        "        //M[idx_start + idx_sh] = B[idx_sh + x_start];\n",
        "    else if(idx_sh > 0)\n",
        "       M_gpu[idx_start + idx_sh] = A_gpu[Y_sh[idx_sh -1]];\n",
        "       M_gpu[idx_start + idx_sh -1] = A_gpu[Y_sh[idx_sh-1]];\n",
        "\n",
        "     __syncthreads();\n",
        "    x_start = X_sh[Z-1];\n",
        "    y_start = Y_sh[Z-1];\n",
        "    idx_start += Z; //update index !!!\n",
        "  }\n",
        "}\n",
        "//########################### WRAPPER FIND PATH ###################################\n",
        "void wrapper_FindPartition(int *a, int dim_A, int *b, int dim_B, int *m, int * x_path, int * y_path){\n",
        "//void wrapper_FindPartition(int *a, int dim_A, int *b, int dim_B, int *m){\n",
        "  int *A_GPU, *B_GPU, *M_GPU, *X_GPU, *Y_GPU;\n",
        "\n",
        "  int count;\n",
        "  cudaDeviceProp prop;\n",
        "  testCUDA(cudaGetDeviceCount(&count));\n",
        "  testCUDA(cudaGetDeviceProperties(&prop, count-1));\n",
        "  printf(\"Global memory size in octet (bytes): %ld \\n\", prop.totalGlobalMem); //ld: long double\n",
        "  printf(\"Max dimension of the two input arrays: %ld \\n\", prop.totalGlobalMem/(sizeof(int)*8)); \n",
        "  printf(\"Shared memory size per block: %ld \\n\", prop.sharedMemPerBlock);\n",
        "  printf(\"Max dimension of the int array in the shared memory: %ld \\n\", prop.sharedMemPerBlock/(sizeof(int)*8)); \n",
        "  printf(\"Number of multiprocessors: %i \\n\", prop.multiProcessorCount); //NSM\n",
        "  printf(\"Maximum number of thread per block: %li \\n\", prop.maxThreadsPerBlock);\n",
        "  //3*2^14 -> 3*2^11\n",
        "\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  testCUDA(cudaMalloc(&A_GPU, dim_A*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&B_GPU, dim_B*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&X_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&Y_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&M_GPU, (dim_A+dim_B)*sizeof(int)));\n",
        "  //Copying the values form one ProcUni to the other ProcUnit\n",
        "  testCUDA(cudaMemcpy(A_GPU, a, dim_A*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(B_GPU, b, dim_B*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  printf(\"Max number of blocks available: %li \\n\",prop.maxGridSize[0] );\n",
        "\n",
        "  printf(\"Number of blocks used: %i \\n\", NSM);\n",
        "  printf(\"Number of thread per block: %i \\n\", Z);\n",
        "  MergePath_partition<<<NSM,1>>>(A_GPU, dim_A, B_GPU, dim_B, X_GPU, Y_GPU);\n",
        "\n",
        "  pathBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, dim_A, dim_B);\n",
        "\n",
        "  mergeBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, M_GPU, dim_A, dim_B);\n",
        "  //Copying the value from one ProcUnit ot the ohter ProcUnit\n",
        "    testCUDA(cudaMemcpy(x_path, X_GPU,(dim_A+dim_B+1)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "    testCUDA(cudaMemcpy(y_path, Y_GPU,(dim_A+dim_B+1)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "    testCUDA(cudaMemcpy(m, M_GPU, (dim_A+dim_B)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  printf(\"Execution time of FIND PATH: %f ms\\n\", TimerV);\n",
        "\n",
        "  //Freeing the GPU MEMORY\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(X_GPU));\n",
        "  testCUDA(cudaFree(Y_GPU));\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "\n",
        "//############################# MAIN ###################################\n",
        "int main(){\n",
        "  //INITIALIZATION:\n",
        "  \n",
        "  int A[] = {1,2,5,6,6,9,11,15,16};// Project exmaple\n",
        "  int B[] = {4,7,8,10,12,13,14};// Project exmaple\n",
        "  int dim_A = 9;// Project exmaple, A is an array with 9 elements\n",
        "  int dim_B = 7;// Project exmaple, B is an array with 7 elements\n",
        "  // The Correct mergesort Path is supposed to be \n",
        "  int  *X_path, *Y_path, *M; //*A, *B,\n",
        "  //int *A, *B, *M;\n",
        "  //int d = 20;\n",
        "  srand (time(NULL));\n",
        "  //int dim_A = rand() % d; // !!!\n",
        "  //int dim_B = d - dim_A;\n",
        "  //if(dim_B > dim_A)\n",
        "    //std::swap(dim_A,dim_B);\n",
        "  //A = (int*)malloc(dim_A*sizeof(int));\n",
        "  //B = (int*)malloc(dim_B*sizeof(int));\n",
        "  //#diagonals == #elements chemin: |A|+|B|+1\n",
        "  X_path = (int*)malloc((dim_A+dim_B+1)*sizeof(int)); // B <-> x\n",
        "  Y_path = (int*)malloc((dim_A+dim_B+1)*sizeof(int)); // A <-> -y\n",
        "  //generate_random(A,dim_A,2,98);\n",
        "  mergesort(A,0,dim_A-1);\n",
        "  //A[0] = 1;\n",
        "  //A[dim_A-1]=100;\n",
        "  //generate_random(B,dim_B,2,98);\n",
        "  mergesort(B,0,dim_B-1);\n",
        "  //B[0] = 0;\n",
        "  //B[dim_B-1] = 101;\n",
        "  assert((dim_A+dim_B)<=1024); //Check: |M| <= 1024\n",
        "  M = (int*)malloc((dim_A+dim_B)*sizeof(int));\n",
        "\n",
        "  // Necessary condition: |A| > |B| !!!\n",
        "    if(dim_A<dim_B)\n",
        "      exchange(A, B, dim_A, dim_B);\n",
        "\n",
        "  printf(\"A: \\n\");\n",
        "  print_array(A,dim_A);\n",
        "\n",
        "  printf(\"B: \\n\");\n",
        "  print_array(B,dim_B);\n",
        "\n",
        "    wrapper_FindPartition(A, dim_A, B, dim_B, M, X_path, Y_path);\n",
        " // wrapper_FindPartition(A, dim_A, B, dim_B, M);\n",
        "\n",
        "  printf(\"M: \\n\");\n",
        "  print_array(M, dim_A+dim_B);\n",
        "\n",
        "\n",
        "    printf(\"Path: \\n\");\n",
        "    for (int i=0; i<5; ++i)\n",
        "    printf(\"X[%i]=%i Y[%i]=%i \\n\",i,X_path[i],i,Y_path[i]);\n",
        "    printf(\"\\n ... \\n\");\n",
        "    for(int i=(dim_A+dim_B-5); i<(dim_A+dim_B+1);++i)\n",
        "    //for(int i=max(0,dim_A+dim_B-5); i<(dim_A+dim_B+1); ++i)\n",
        "    printf(\"X[%i]=%i Y[%i]=%i \\n\",i,X_path[i],i,Y_path[i]);\n",
        "    printf(\"Path: \\n\");\n",
        "    for (int i=0; i<dim_A+dim_B+1; ++i)\n",
        "    printf(\"X[%i]=%i Y[%i]=%i \\n\",i,X_path[i],i,Y_path[i]); \n",
        "    printf(\"\\n\");\n",
        "\n",
        "  //free(A);\n",
        "  //free(B);\n",
        "  free(M);\n",
        "  free(X_path);\n",
        "  free(Y_path);\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-qkMDtQfITr",
        "outputId": "402f0201-1d79-4d67-dfb3-a9ee5a641132"
      },
      "source": [
        "!cd src && make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(27): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "main.cu(77): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "main.cu(146): warning: variable \"A_sh\" was set but never used\n",
            "\n",
            "main.cu(146): warning: variable \"B_sh\" was set but never used\n",
            "\n",
            "\u001b[01m\u001b[Kmain.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid wrapper_FindPartition(int*, int, int*, int, int*, int*, int*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmain.cu:193:77:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Maximum number of thread per block: %li \\n\"\u001b[32m\u001b[K, prop.maxThreadsPerBlo\u001b[m\u001b[K\u001b[01;35m\u001b[Kc\u001b[m\u001b[Kk);\n",
            "                                                      \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cu:211:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Max number of blocks available: %li \\n\"\u001b[32m\u001b[K,prop.maxGridSize[0] \u001b[m\u001b[K\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                  \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZaO0_T2fRVE",
        "outputId": "89b9d748-92de-422d-f43d-a0529979deda"
      },
      "source": [
        "!cd src && make run "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "A: \n",
            "dim: 9 \n",
            "1 2 5 6 6 9 11 15 16 \n",
            "B: \n",
            "dim: 7 \n",
            "4 7 8 10 12 13 14 \n",
            "Global memory size in octet (bytes): 17071734784 \n",
            "Max dimension of the two input arrays: 533491712 \n",
            "Shared memory size per block: 49152 \n",
            "Max dimension of the int array in the shared memory: 1536 \n",
            "Number of multiprocessors: 56 \n",
            "Maximum number of thread per block: 1024 \n",
            "Max number of blocks available: 2147483647 \n",
            "Number of blocks used: 4096 \n",
            "Number of thread per block: 32 \n",
            "X[0] = 3, Y[0] = 5X[0] = 4, Y[0] = 7X[0] = 7, Y[0] = 7X[0] = 0, Y[0] = 1X[0] = 1, Y[0] = 5X[0] = 3, Y[0] = 6X[0] = 1, Y[0] = 2X[0] = 1, Y[0] = 4X[0] = 6, Y[0] = 7X[0] = 2, Y[0] = 5X[0] = 0, Y[0] = 2X[0] = 4, Y[0] = 6X[0] = 1, Y[0] = 3X[0] = 7, Y[0] = 8X[0] = 5, Y[0] = 7X[0] = 7, Y[0] = 9Execution time of FIND PATH: 0.519104 ms\n",
            "M: \n",
            "dim: 16 \n",
            "1 1 1 5 1 1 7 1 1 10 1 1 13 1 1 16 \n",
            "Path: \n",
            "X[0]=0 Y[0]=0 \n",
            "X[1]=0 Y[1]=1 \n",
            "X[2]=0 Y[2]=2 \n",
            "X[3]=1 Y[3]=2 \n",
            "X[4]=1 Y[4]=3 \n",
            "\n",
            " ... \n",
            "X[11]=4 Y[11]=7 \n",
            "X[12]=5 Y[12]=7 \n",
            "X[13]=6 Y[13]=7 \n",
            "X[14]=7 Y[14]=7 \n",
            "X[15]=7 Y[15]=8 \n",
            "X[16]=7 Y[16]=9 \n",
            "Path: \n",
            "X[0]=0 Y[0]=0 \n",
            "X[1]=0 Y[1]=1 \n",
            "X[2]=0 Y[2]=2 \n",
            "X[3]=1 Y[3]=2 \n",
            "X[4]=1 Y[4]=3 \n",
            "X[5]=1 Y[5]=4 \n",
            "X[6]=1 Y[6]=5 \n",
            "X[7]=2 Y[7]=5 \n",
            "X[8]=3 Y[8]=5 \n",
            "X[9]=3 Y[9]=6 \n",
            "X[10]=4 Y[10]=6 \n",
            "X[11]=4 Y[11]=7 \n",
            "X[12]=5 Y[12]=7 \n",
            "X[13]=6 Y[13]=7 \n",
            "X[14]=7 Y[14]=7 \n",
            "X[15]=7 Y[15]=8 \n",
            "X[16]=7 Y[16]=9 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N40nGZsqFo6j"
      },
      "source": [
        "# Execution time algorithm 1.2 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hly2NQZ4FyaW",
        "outputId": "a992591f-b79c-46c4-b898-e637c807e975"
      },
      "source": [
        "%%cuda --name main.cu\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include<algorithm>\n",
        "#include\"repos/functions/functions.hpp\"\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "#define NSM 4096 //optimal for execution time \n",
        "// 56 = number of multiprocessors -> prop.multiProcessorCount\n",
        "#define Z 32\n",
        "\n",
        "//############ KERNEL - find MERGE PATH in the PARTITION POINTS ##############\n",
        "//X_path -> horizontal (>) <-> \"B\"-direction\n",
        "//Y_path -> vertical (v) <-> \"A\"-direction\n",
        "__global__ void MergePath_partition(int *A_gpu, int dim_A, int *B_gpu, int dim_B, int *X_gpu, int *Y_gpu){\n",
        "//Divide the work among the processors: PARTITIONING\n",
        "//\"idx\" is the PARTITIONS: it goes from 0 to #partitions (=#NSM)\n",
        "  int idx = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A+dim_B);\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "  //Cross diagonal binary search for MERGE PATH at the PARTITION POINTS on GLOBAL MEMORY\n",
        "  //Writing the MERGE PATH at PARTITION POINTS on the GLOBAL MEMORY\n",
        "    if(idx>dim_A){\n",
        "      K_x = idx - dim_A; //(K_x, K_y): low point of diagonal\n",
        "      K_y = dim_A;\n",
        "      P_x = dim_A;      //(P_x,P_y): high point of diagonal\n",
        "      P_y = idx - dim_A;\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = idx;\n",
        "      P_x = idx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);// integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if (Q_y>=0 && Q_x<=dim_B && (Q_y == dim_A || Q_x==0 || A_gpu[Q_y] > B_gpu[Q_x-1]) ){\n",
        "      // A[Q_y]>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if (Q_x == dim_B || Q_y == 0 || A_gpu[Q_y-1] <= B_gpu[Q_x]){\n",
        "          // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q' -> Q is on the \"path\"\n",
        "                X_gpu[idx] = Q_x;\n",
        "                Y_gpu[idx] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  //The Merge Path terminates in the point (dim_B, dim_A):\n",
        "  if(blockIdx.x==0 && threadIdx.x==0){\n",
        "    X_gpu[dim_A+dim_B] = dim_B;\n",
        "    Y_gpu[dim_A+dim_B] = dim_A;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "//######################### KERNEL - BIG PATH #################################\n",
        "__global__ void pathBig_k(int *X_gpu, int *Y_gpu, const int *A_gpu, const int *B_gpu, int dim_A, int dim_B){\n",
        "  //idx_start, idx_end: beginning of the partition, end of the partition\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  //x_start, y_start: coordinates of the first element of the MergePath in the partition\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  //Place Z elements from each input array in the SHARED MEMORY for each partition\n",
        "  __shared__ int A_sh[Z], B_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "//Cross diagonal binary search for MERGE PATH on SHARED MEMORY\n",
        "//Writing the MERGE PATH on the GLOBAL MEMORY\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "   //Placing the input arrays in the SHARED MEMORY\n",
        "  if(idx_sh + y_start < dim_A) //in order to have valid indexes for \"A_sh\" and \"A_gpu\"\n",
        "    A_sh[idx_sh] = A_gpu[idx_sh + y_start];\n",
        "  if(idx_sh + x_start < dim_B)\n",
        "    B_sh[idx_sh] = B_gpu[idx_sh + x_start];\n",
        "\n",
        "    if(idx_sh + y_start + 1 > dim_A){\n",
        "      //since we know already the Merge Path at the starting point: (x_start, y_start)\n",
        "      //we want to look for the Merge Path from the \"next diagonal\", that's why \"+1\"\n",
        "      K_x = x_start + (idx_sh + y_start + 1 - dim_A);\n",
        "      K_y = dim_A;\n",
        "      } else{\n",
        "        K_x = x_start;\n",
        "        K_y = idx_sh + y_start + 1;\n",
        "        }\n",
        "    if(idx_sh + x_start + 1 > dim_B){\n",
        "      P_x = dim_B;\n",
        "      P_y = y_start + (idx_sh + x_start + 1 - dim_B);\n",
        "      } else{\n",
        "        P_x = idx_sh + x_start + 1;\n",
        "        P_y = y_start;\n",
        "      }\n",
        "\n",
        "      while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if ((Q_y>=y_start && Q_y>=0) && (Q_x<=(Z+x_start)<=dim_B) && ((Q_y == (Z+y_start) || Q_y == dim_A) || (Q_x==x_start || Q_x==0) || A_sh[Q_y - y_start] > B_sh[Q_x -1 - x_start]) ){\n",
        "      // A[Q_y>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if ((Q_x == (Z+x_start) || Q_x == dim_B) || (Q_y == y_start || Q_y == 0) || A_sh[Q_y -1 - y_start] <= B_sh[Q_x - x_start]){\n",
        "                X_gpu[idx_start + idx_sh + 1] = Q_x;\n",
        "                Y_gpu[idx_start + idx_sh + 1] = Q_y;\n",
        "\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    //Updating the indexes:\n",
        "    x_start = X_gpu[idx_start + Z]; //x_start = x_end\n",
        "    y_start = Y_gpu[idx_start + Z]; //y_start = y_end\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "\n",
        "//######################### KERNEL to MERGE  ##################################\n",
        "__global__ void mergeBig_k(int *X_gpu, int *Y_gpu, int *A_gpu, int *B_gpu, int *M_gpu, int dim_A, int dim_B){\n",
        "\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  //Place Z ponits of the MERGE PATH in the SHARED MEMORY\n",
        "  __shared__ int X_sh[Z], Y_sh[Z];\n",
        "\n",
        "  int idx_sh = threadIdx.x;\n",
        "\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "   //Placing the MERGE PATH in the SHARED MEMORY\n",
        "    X_sh[idx_sh] = X_gpu[idx_start + idx_sh + 1];\n",
        "    Y_sh[idx_sh] = Y_gpu[idx_start + idx_sh + 1];\n",
        "\n",
        "    if(idx_sh == 0 && X_sh[0] > x_start) //If the path is moving right\n",
        "      M_gpu[idx_start] = B_gpu[x_start];\n",
        "    else if(idx_sh ==0) //if the path is moving down\n",
        "      M_gpu[idx_start] = A_gpu[y_start];\n",
        "\n",
        "    if( idx_sh> 0 && X_sh[idx_sh]>X_sh[idx_sh-1]) //If the path is moving right\n",
        "      M_gpu[idx_start + idx_sh] = B_gpu[X_sh[idx_sh -1]];\n",
        "    else if(idx_sh > 0) //if the path is moving down\n",
        "      M_gpu[idx_start + idx_sh] = A_gpu[Y_sh[idx_sh -1]];\n",
        "\n",
        "    //Update the indexes\n",
        "    x_start = X_sh[Z-1];\n",
        "    y_start = Y_sh[Z-1];\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "//########################### WRAPPER FIND PATH ###################################\n",
        "void wrapper_MergeSort(int *a, int dim_A, int *b, int dim_B, int *m, float & duration){\n",
        "  int *A_GPU, *B_GPU, *M_GPU, *X_GPU, *Y_GPU;\n",
        "\n",
        "  int count;\n",
        "  cudaDeviceProp prop;\n",
        "  testCUDA(cudaGetDeviceCount(&count));\n",
        "  testCUDA(cudaGetDeviceProperties(&prop, count-1));\n",
        "\n",
        "  //Initilizating the timer:\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  //Initialization on GPU:\n",
        "  testCUDA(cudaMalloc(&A_GPU, dim_A*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&B_GPU, dim_B*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&X_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&Y_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&M_GPU, (dim_A+dim_B)*sizeof(int)));\n",
        "\n",
        "  testCUDA(cudaMemcpy(A_GPU, a, dim_A*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(B_GPU, b, dim_B*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  //##### KERNEL CALLS ######\n",
        "  MergePath_partition<<<NSM,1>>>(A_GPU, dim_A, B_GPU, dim_B, X_GPU, Y_GPU);\n",
        "\n",
        "  pathBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, dim_A, dim_B);\n",
        "\n",
        "  mergeBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, M_GPU, dim_A, dim_B);\n",
        "\n",
        "  //Bringing back the results from GPU to CPU:\n",
        "  testCUDA(cudaMemcpy(m, M_GPU, (dim_A+dim_B)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  //Stop the timer:\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  printf(\"Execution time: %f\\n \\n\", TimerV);\n",
        "  duration = TimerV;\n",
        "\n",
        "  //Freeing the GPU MEMORY\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(X_GPU));\n",
        "  testCUDA(cudaFree(Y_GPU));\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "\n",
        "//############################# MAIN ###################################\n",
        "int main(){\n",
        "  //Initialization\n",
        "  int *A, *B, *M;\n",
        "  int d[20];\n",
        "  float duration[20];\n",
        "  for(int i=0; i<20; ++i)\n",
        "    d[i] = pow(2,i+1); //2, 4, 8, 16, ..., 1.000.000\n",
        "  d[19] = 1e6;\n",
        "\n",
        "  for(int k=0; k<20; k++){\n",
        "    srand (time(NULL));\n",
        "    int dim_A = rand() % (d[k]-1) + 1; //choosing randomly the dimension\n",
        "    int dim_B = d[k] - dim_A;\n",
        "    if(dim_B > dim_A) //necessary condition: |A| > |B|\n",
        "      std::swap(dim_A,dim_B);\n",
        "    A = (int*)malloc(dim_A*sizeof(int));\n",
        "    B = (int*)malloc(dim_B*sizeof(int));\n",
        "    generate_random(A,dim_A,0,1000); //random generation of the input arrays\n",
        "    A[dim_A/2] = 1000;\n",
        "    mergesort(A,0,dim_A-1);\n",
        "    generate_random(B,dim_B,0,1000);\n",
        "    B[dim_B/2] = -1;\n",
        "    mergesort(B,0,dim_B-1);\n",
        "    M = (int*)malloc((dim_A+dim_B)*sizeof(int));\n",
        "\n",
        "    \n",
        "    printf(\"%i)\\nA: \\n\",k);\n",
        "    print_array(A,dim_A);\n",
        "    printf(\"\\n\");\n",
        "    \n",
        "    printf(\"B: \\n\");\n",
        "    print_array(B,dim_B);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    //###### WRAPPER CALL ######\n",
        "    wrapper_MergeSort(A, dim_A, B, dim_B, M, duration[k]);\n",
        "\n",
        "\n",
        "    \n",
        "    printf(\"M: \\n\");\n",
        "    print_array(M, dim_A+dim_B);\n",
        "    printf(\"\\n \\n \\n\");\n",
        "\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(M);\n",
        "  }\n",
        "}\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%cuda` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYC6Y3imQkId",
        "outputId": "38ef1389-83b1-40c8-c9cd-d320896cabf3"
      },
      "source": [
        "!cd src && make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(20): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "main.cu(76): warning: variable \"P_x\" was set but never used\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ1KExlHQ21t",
        "outputId": "e3ce64ce-ed61-4aa0-8f07-b2ee9f18867d"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "0)\n",
            "A: \n",
            "dim: 1 \n",
            "1000 \n",
            "\n",
            "B: \n",
            "dim: 1 \n",
            "-1 \n",
            "\n",
            "Execution time: 0.273760\n",
            " \n",
            "M: \n",
            "dim: 2 \n",
            "-1 1000 \n",
            "\n",
            " \n",
            " \n",
            "1)\n",
            "A: \n",
            "dim: 3 \n",
            "121 257 1000 \n",
            "\n",
            "B: \n",
            "dim: 1 \n",
            "-1 \n",
            "\n",
            "Execution time: 0.209344\n",
            " \n",
            "M: \n",
            "dim: 4 \n",
            "-1 121 257 1000 \n",
            "\n",
            " \n",
            " \n",
            "2)\n",
            "A: \n",
            "dim: 5 \n",
            "257 482 609 983 1000 \n",
            "\n",
            "B: \n",
            "dim: 3 \n",
            "-1 536 770 \n",
            "\n",
            "Execution time: 0.193408\n",
            " \n",
            "M: \n",
            "dim: 8 \n",
            "-1 257 482 536 609 770 983 1000 \n",
            "\n",
            " \n",
            " \n",
            "3)\n",
            "A: \n",
            "dim: 12 \n",
            "93 121 257 273 482 536 605 609 618 770 983 1000 \n",
            "\n",
            "B: \n",
            "dim: 4 \n",
            "-1 300 591 698 \n",
            "\n",
            "Execution time: 0.188800\n",
            " \n",
            "M: \n",
            "dim: 16 \n",
            "-1 93 121 257 273 300 482 536 591 605 609 618 698 770 983 1000 \n",
            "\n",
            " \n",
            " \n",
            "4)\n",
            "A: \n",
            "dim: 27 \n",
            "93 111 121 190 207 233 257 273 300 308  ... 604 605 609 618 653 684 770 875 983 1000 \n",
            "\n",
            "B: \n",
            "dim: 5 \n",
            "-1 339 626 708 948 \n",
            "\n",
            "Execution time: 0.164832\n",
            " \n",
            "M: \n",
            "dim: 32 \n",
            "-1 93 111 121 190 207 233 257 273 300  ... 618 626 653 684 708 770 875 948 983 1000 \n",
            "\n",
            " \n",
            " \n",
            "5)\n",
            "A: \n",
            "dim: 52 \n",
            "44 90 93 100 111 121 190 207 233 257  ... 708 770 779 870 875 933 939 948 983 1000 \n",
            "\n",
            "B: \n",
            "dim: 12 \n",
            "-1 145 197 315 316 506 511 522 561 794 837 881 \n",
            "\n",
            "Execution time: 0.175776\n",
            " \n",
            "M: \n",
            "dim: 64 \n",
            "-1 44 90 93 100 111 121 145 190 197  ... 794 837 870 875 881 933 939 948 983 1000 \n",
            "\n",
            " \n",
            " \n",
            "6)\n",
            "A: \n",
            "dim: 74 \n",
            "44 93 100 111 121 131 145 190 197 198  ... 837 870 875 881 883 933 939 948 983 1000 \n",
            "\n",
            "B: \n",
            "dim: 54 \n",
            "-1 3 95 100 152 157 189 232 294 297  ... 894 909 937 952 957 972 976 981 989 990 \n",
            "\n",
            "Execution time: 0.166848\n",
            " \n",
            "M: \n",
            "dim: 128 \n",
            "-1 3 44 93 95 100 100 111 121 131  ... 948 952 957 972 976 981 983 989 990 1000 \n",
            "\n",
            " \n",
            " \n",
            "7)\n",
            "A: \n",
            "dim: 139 \n",
            "3 3 44 84 87 90 93 95 100 100  ... 957 972 976 981 983 989 990 992 995 1000 \n",
            "\n",
            "B: \n",
            "dim: 117 \n",
            "-1 1 1 11 16 19 25 27 37 43  ... 934 936 947 962 969 970 970 976 984 992 \n",
            "\n",
            "Execution time: 0.167424\n",
            " \n",
            "M: \n",
            "dim: 256 \n",
            "-1 1 1 3 3 11 16 19 25 27  ... 976 981 983 984 989 990 992 992 995 1000 \n",
            "\n",
            " \n",
            " \n",
            "8)\n",
            "A: \n",
            "dim: 304 \n",
            "1 1 3 3 11 16 19 25 27 37  ... 980 981 983 984 989 990 992 992 995 1000 \n",
            "\n",
            "B: \n",
            "dim: 208 \n",
            "-1 3 8 12 19 22 26 28 35 36  ... 954 955 961 962 968 973 986 987 996 999 \n",
            "\n",
            "Execution time: 0.167200\n",
            " \n",
            "M: \n",
            "dim: 512 \n",
            "-1 1 1 3 3 3 8 11 12 16  ... 986 987 989 990 992 992 995 996 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "9)\n",
            "A: \n",
            "dim: 616 \n",
            "1 1 3 3 3 3 6 8 11 12  ... 986 987 989 990 992 992 995 996 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 408 \n",
            "-1 0 3 3 4 6 7 13 15 15  ... 974 976 978 988 990 991 991 995 998 998 \n",
            "\n",
            "Execution time: 0.180736\n",
            " \n",
            "M: \n",
            "dim: 1024 \n",
            "-1 0 1 1 3 3 3 3 3 3  ... 991 992 992 995 995 996 998 998 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "10)\n",
            "A: \n",
            "dim: 1054 \n",
            "0 0 1 1 3 3 3 3 3 3  ... 992 992 995 995 995 996 998 998 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 994 \n",
            "-1 3 3 3 5 5 6 8 10 10  ... 992 994 995 995 995 996 996 997 998 999 \n",
            "\n",
            "Execution time: 0.196704\n",
            " \n",
            "M: \n",
            "dim: 2048 \n",
            "-1 0 0 1 1 3 3 3 3 3  ... 996 996 996 997 998 998 998 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "11)\n",
            "A: \n",
            "dim: 2217 \n",
            "0 0 1 1 3 3 3 3 3 3  ... 996 996 996 997 998 998 998 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 1879 \n",
            "-1 0 0 1 2 3 4 4 4 5  ... 996 996 997 998 998 998 998 998 999 999 \n",
            "\n",
            "Execution time: 0.195360\n",
            " \n",
            "M: \n",
            "dim: 4096 \n",
            "-1 0 0 0 0 1 1 1 2 3  ... 998 998 998 998 998 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "12)\n",
            "A: \n",
            "dim: 8000 \n",
            "0 0 0 0 0 0 0 1 1 1  ... 998 998 998 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 192 \n",
            "-1 16 21 33 35 38 40 45 46 65  ... 947 952 953 963 963 973 975 997 997 997 \n",
            "\n",
            "Execution time: 0.217056\n",
            " \n",
            "M: \n",
            "dim: 8192 \n",
            "-1 0 0 0 0 0 0 0 1 1  ... 998 998 998 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "13)\n",
            "A: \n",
            "dim: 13663 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 998 998 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 2721 \n",
            "-1 0 0 0 0 0 1 1 1 1  ... 996 996 997 997 997 998 998 998 999 999 \n",
            "\n",
            "Execution time: 0.242624\n",
            " \n",
            "M: \n",
            "dim: 16384 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "14)\n",
            "A: \n",
            "dim: 20394 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 12374 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 999 \n",
            "\n",
            "Execution time: 0.300608\n",
            " \n",
            "M: \n",
            "dim: 32768 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "15)\n",
            "A: \n",
            "dim: 48334 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 17202 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 999 \n",
            "\n",
            "Execution time: 0.400544\n",
            " \n",
            "M: \n",
            "dim: 65536 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "16)\n",
            "A: \n",
            "dim: 68768 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 62304 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 999 \n",
            "\n",
            "Execution time: 0.704128\n",
            " \n",
            "M: \n",
            "dim: 131072 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "17)\n",
            "A: \n",
            "dim: 192855 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 69289 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 999 \n",
            "\n",
            "Execution time: 1.295904\n",
            " \n",
            "M: \n",
            "dim: 262144 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "18)\n",
            "A: \n",
            "dim: 334925 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 189363 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 999 \n",
            "\n",
            "Execution time: 2.040288\n",
            " \n",
            "M: \n",
            "dim: 524288 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n",
            "19)\n",
            "A: \n",
            "dim: 998602 \n",
            "0 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            "B: \n",
            "dim: 1398 \n",
            "-1 1 2 2 2 3 4 4 5 7  ... 996 996 996 997 997 997 998 998 999 999 \n",
            "\n",
            "Execution time: 2.938944\n",
            " \n",
            "M: \n",
            "dim: 1000000 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 999 999 999 999 999 999 999 999 999 1000 \n",
            "\n",
            " \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXyB7EOFM6Yf"
      },
      "source": [
        "# Question 1.3 : Parallel MergeSort "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hNVZkAftM53u",
        "outputId": "f7227e59-1677-4243-b97c-73ccb3da8e2a"
      },
      "source": [
        "%%cuda --name main.cu\n",
        "/* Looping on appropriate calls of \"pathBig_k\" and \"mergeBig_k\", write a function that sorts any array \"M\" of size \"d\" sufficiently smaller than the global memory. Give the execution time with respect to \"d\" */\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include<fstream> //to export data\n",
        "#include<algorithm>\n",
        "#include\"repos/functions/functions.hpp\"\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "#define NSM 4096\n",
        "#define Z 32\n",
        "\n",
        "//#################### KERNEL - find MERGE PATH in the PARTITION POINTS ##############################\n",
        "__global__ void MergePath_partition(int *A_gpu, int dim_A, int *B_gpu, int dim_B, int *X_gpu, int *Y_gpu){\n",
        "  int idx = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A+dim_B);\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "    if(idx>dim_A){\n",
        "      K_x = idx - dim_A;\n",
        "      K_y = dim_A;\n",
        "      P_x = dim_A;\n",
        "      P_y = idx - dim_A;\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = idx;\n",
        "      P_x = idx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);//integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if (Q_y>=0 && Q_x<=dim_B && (Q_y == dim_A || Q_x==0 || A_gpu[Q_y] > B_gpu[Q_x-1]) ){\n",
        "          if (Q_x == dim_B || Q_y == 0 || A_gpu[Q_y-1] <= B_gpu[Q_x]){\n",
        "                X_gpu[idx] = Q_x;\n",
        "                Y_gpu[idx] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  if(blockIdx.x==0 && threadIdx.x==0){\n",
        "    X_gpu[dim_A+dim_B] = dim_B;\n",
        "    Y_gpu[dim_A+dim_B] = dim_A;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "//######################### KERNEL - BIG PATH #################################\n",
        "__global__ void pathBig_k(int *X_gpu, int *Y_gpu, const int *A_gpu, const int *B_gpu, int dim_A, int dim_B){\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  __shared__ int A_sh[Z], B_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "  if(idx_sh + y_start < dim_A)\n",
        "    A_sh[idx_sh] = A_gpu[idx_sh + y_start];\n",
        "  if(idx_sh + x_start< dim_B)\n",
        "    B_sh[idx_sh] = B_gpu[idx_sh + x_start];\n",
        "    if(idx_sh + y_start + 1 > dim_A){\n",
        "      K_x = x_start + (idx_sh + y_start + 1 - dim_A);\n",
        "      K_y = dim_A;\n",
        "      } else{\n",
        "        K_x = x_start;\n",
        "        K_y = idx_sh + y_start + 1;\n",
        "        }\n",
        "    if(idx_sh + x_start + 1 > dim_B){\n",
        "      P_x = dim_B;\n",
        "      P_y = y_start + (idx_sh + x_start + 1 - dim_B);\n",
        "      } else{\n",
        "        P_x = idx_sh + x_start + 1;\n",
        "        P_y = y_start;\n",
        "      }\n",
        "\n",
        "      while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);// integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if ((Q_y>=y_start && Q_y>=0) && (Q_x<=(Z+x_start)<=dim_B) && ((Q_y == (Z+y_start) || Q_y == dim_A) || (Q_x==x_start || Q_x==0) || A_sh[Q_y - y_start] > B_sh[Q_x -1 - x_start]) ){\n",
        "          if ((Q_x == (Z+x_start) || Q_x == dim_B) || (Q_y == y_start || Q_y == 0) || A_sh[Q_y -1 - y_start] <= B_sh[Q_x - x_start]){\n",
        "                X_gpu[idx_start + idx_sh +1] = Q_x;\n",
        "                Y_gpu[idx_start + idx_sh +1] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "    x_start = X_gpu[idx_start + Z];\n",
        "    y_start = Y_gpu[idx_start + Z];\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "\n",
        "//######################### KERNEL to MERGE  ##################################\n",
        "__global__ void mergeBig_k(int *X_gpu, int *Y_gpu, int *A_gpu, int *B_gpu, int *M_gpu, int dim_A, int dim_B){\n",
        "\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  __shared__ int X_sh[Z], Y_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "    X_sh[idx_sh] = X_gpu[idx_start + idx_sh + 1];\n",
        "    Y_sh[idx_sh] = Y_gpu[idx_start + idx_sh + 1];\n",
        "    if(idx_sh == 0 && X_sh[0] > x_start)\n",
        "      M_gpu[idx_start] = B_gpu[x_start];\n",
        "    else if(idx_sh ==0)\n",
        "      M_gpu[idx_start] = A_gpu[y_start];\n",
        "\n",
        "    if( idx_sh>0 && X_sh[idx_sh]>X_sh[idx_sh-1])\n",
        "      M_gpu[idx_start + idx_sh] = B_gpu[X_sh[idx_sh -1]];\n",
        "    else if(idx_sh > 0)\n",
        "      M_gpu[idx_start + idx_sh] = A_gpu[Y_sh[idx_sh -1]];\n",
        "\n",
        "    x_start = X_sh[Z-1];\n",
        "    y_start = Y_sh[Z-1];\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "//########################### WRAPPER FIND PATH ###################################\n",
        "void wrapper_FindPartition(int *a, int dim_A, int *b, int dim_B, int *m){\n",
        "  int *A_GPU, *B_GPU, *M_GPU, *X_GPU, *Y_GPU;\n",
        "\n",
        "  testCUDA(cudaMalloc(&A_GPU, dim_A*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&B_GPU, dim_B*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&X_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&Y_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&M_GPU, (dim_A+dim_B)*sizeof(int)));\n",
        "\n",
        "  testCUDA(cudaMemcpy(A_GPU, a, dim_A*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(B_GPU, b, dim_B*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  MergePath_partition<<<NSM,1>>>(A_GPU, dim_A, B_GPU, dim_B, X_GPU, Y_GPU);\n",
        "\n",
        "  pathBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, dim_A, dim_B);\n",
        "\n",
        "  mergeBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, M_GPU, dim_A, dim_B);\n",
        "\n",
        "  testCUDA(cudaMemcpy(m, M_GPU, (dim_A+dim_B)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(X_GPU));\n",
        "  testCUDA(cudaFree(Y_GPU));\n",
        "}\n",
        "\n",
        "//####################### PARALLEL MERGE SORT ############################\n",
        "int * merge_parallel (int *T , int p, int q, int r){\n",
        "  //A: fisrt array, B: second array, M_suport: mergesorted array\n",
        "  int *A, *B, *M_support;\n",
        "  int dim_A = q-p+1;\n",
        "  int dim_B = r-q;\n",
        "  if(dim_B > dim_A)\n",
        "    std::swap(dim_A,dim_B);\n",
        "  A = (int*)malloc(dim_A*sizeof(int));\n",
        "  B = (int*)malloc(dim_B*sizeof(int));\n",
        "  for(int i=0, j=p; i<q-p+1; ++i, ++j) //I copy in A the first array\n",
        "    A[i] = T[j];\n",
        "  for(int i=0, j=q+1; i<r-q; ++i, ++j) //I copy in B the second array\n",
        "    B[i] = T[j];\n",
        "  M_support = (int*)malloc((dim_A+dim_B)*sizeof(int));\n",
        "\n",
        "//###### WRAPPER CALL #######\n",
        "  wrapper_FindPartition(A, dim_A, B, dim_B, M_support);\n",
        "\n",
        "  for(int i=p, j=0; i<=r; ++i, ++j) //I copy the sorted array into the original one\n",
        "    T[i]=M_support[j];\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(M_support);\n",
        "  return T;\n",
        "}\n",
        "\n",
        "int * mergesort_parallel(int* T,int p,int r){\n",
        "  if(p<r){ //It stops when p == r -> if(p!=r) -> it breaks in \"SINGLETON\"\n",
        "//if(r-p<1e6)\n",
        "    int q = floor((p+r)/2); //It divides the block {p,p+1,..,r} into two sub-blocks: {p,..,q} e {q+1,..,r}\n",
        "    //I sort recursively the two sub-blocks\n",
        "    //until I get two singletons (p==r): I SORT the SINGLETONS and then I FUSION them\n",
        "    mergesort_parallel(T,p,q);\n",
        "    mergesort_parallel(T,q+1,r);\n",
        "    merge_parallel(T,p,q,r);\n",
        "  }\n",
        "  return T;\n",
        "}\n",
        "\n",
        "void parallel_sort(int* T, int N){\n",
        "  mergesort_parallel(T,0,N-1);\n",
        "}\n",
        "\n",
        "//############################# MAIN ###################################\n",
        "int main(){\n",
        "//###### INITIALIZATION ######\n",
        "  int *M;\n",
        "  int d[20];\n",
        "  float duration[20];\n",
        "  for(int i=0; i<20; ++i)\n",
        "    d[i] = pow(2,i+1);\n",
        "  d[19] = 1e6;\n",
        "\n",
        "  for(int k=0; k<20; ++k){\n",
        "  srand (time(NULL));\n",
        "  M = (int*)malloc(d[k]*sizeof(int));\n",
        "  generate_random(M,d[k],0,100);\n",
        "  M[d[k]/2] = -1; //just to check if it sorted correctly\n",
        "  printf(\"M %i: \\n\", k);\n",
        "  print_array(M, d[k]);\n",
        "\n",
        "  //Initializating the timer:\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "\n",
        "\n",
        "//######### PARALLEL MERGE SORT ##############\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  parallel_sort(M,d[k]);\n",
        "\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  duration[k] = TimerV;\n",
        "\n",
        "  printf(\"M sorted %i: \\n\", k);\n",
        "  print_array(M, d[k]);\n",
        "\n",
        "  printf(\"\\n\");\n",
        "  free(M);\n",
        "\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "for(int k=0; k<20; k++)\n",
        "  printf(\"Execution time with N = %i: %f ms\\n\", d[k], duration[k]);\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRUbfwzjN8x_",
        "outputId": "05b48322-97be-41e4-aa2e-2cfd95fe83ef"
      },
      "source": [
        "!cd src && make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(18): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "main.cu(66): warning: variable \"P_x\" was set but never used\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XIh21VNOBdy",
        "outputId": "e7295b95-87eb-446d-8e62-f1e717c044b8"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "M 0: \n",
            "dim: 2 \n",
            "41 -1 \n",
            "M sorted 0: \n",
            "dim: 2 \n",
            "-1 41 \n",
            "\n",
            "M 1: \n",
            "dim: 4 \n",
            "41 62 -1 49 \n",
            "M sorted 1: \n",
            "dim: 4 \n",
            "-1 41 49 62 \n",
            "\n",
            "M 2: \n",
            "dim: 8 \n",
            "41 62 6 49 -1 27 26 95 \n",
            "M sorted 2: \n",
            "dim: 8 \n",
            "-1 6 26 27 41 49 62 95 \n",
            "\n",
            "M 3: \n",
            "dim: 16 \n",
            "41 62 6 49 0 27 26 95 -1 46 25 79 56 66 50 68 \n",
            "M sorted 3: \n",
            "dim: 16 \n",
            "-1 0 6 25 26 27 41 46 49 50 56 62 66 68 79 95 \n",
            "\n",
            "M 4: \n",
            "dim: 32 \n",
            "41 62 6 49 0 27 26 95 73 46  ... 12 96 43 18 81 9 85 34 54 78 \n",
            "M sorted 4: \n",
            "dim: 32 \n",
            "-1 0 6 9 10 12 14 18 19 25  ... 66 68 73 74 78 79 81 85 95 96 \n",
            "\n",
            "M 5: \n",
            "dim: 64 \n",
            "41 62 6 49 0 27 26 95 73 46  ... 77 68 84 10 77 21 44 32 51 93 \n",
            "M sorted 5: \n",
            "dim: 64 \n",
            "-1 0 1 4 6 9 10 10 12 12  ... 79 81 84 85 93 95 96 96 96 99 \n",
            "\n",
            "M 6: \n",
            "dim: 128 \n",
            "66 44 85 1 23 92 28 11 38 37  ... 2 37 9 43 95 78 29 3 25 82 \n",
            "M sorted 6: \n",
            "dim: 128 \n",
            "-1 1 1 1 1 1 1 1 2 3  ... 92 93 95 95 95 95 96 96 97 98 \n",
            "\n",
            "M 7: \n",
            "dim: 256 \n",
            "66 44 85 1 23 92 28 11 38 37  ... 96 52 5 99 87 98 77 85 74 59 \n",
            "M sorted 7: \n",
            "dim: 256 \n",
            "-1 0 0 1 1 1 1 1 1 1  ... 96 97 97 97 98 98 99 99 99 99 \n",
            "\n",
            "M 8: \n",
            "dim: 512 \n",
            "66 44 85 1 23 92 28 11 38 37  ... 10 87 6 67 39 13 21 51 75 37 \n",
            "M sorted 8: \n",
            "dim: 512 \n",
            "-1 0 0 0 1 1 1 1 1 1  ... 97 98 98 98 99 99 99 99 99 99 \n",
            "\n",
            "M 9: \n",
            "dim: 1024 \n",
            "66 44 85 1 23 92 28 11 38 37  ... 13 67 13 37 59 87 97 50 75 78 \n",
            "M sorted 9: \n",
            "dim: 1024 \n",
            "-1 0 0 0 0 0 1 1 1 1  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 10: \n",
            "dim: 2048 \n",
            "66 44 85 1 23 92 28 11 38 37  ... 25 62 4 86 66 72 2 68 72 62 \n",
            "M sorted 10: \n",
            "dim: 2048 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 11: \n",
            "dim: 4096 \n",
            "66 44 85 1 23 92 28 11 38 37  ... 54 55 37 48 64 59 77 14 23 14 \n",
            "M sorted 11: \n",
            "dim: 4096 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 12: \n",
            "dim: 8192 \n",
            "61 59 23 75 19 9 71 53 21 8  ... 42 99 39 40 20 21 90 18 82 41 \n",
            "M sorted 12: \n",
            "dim: 8192 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 13: \n",
            "dim: 16384 \n",
            "68 9 36 55 96 96 49 86 82 73  ... 74 85 66 98 81 97 33 60 35 42 \n",
            "M sorted 13: \n",
            "dim: 16384 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 14: \n",
            "dim: 32768 \n",
            "81 1 5 26 40 65 3 56 6 85  ... 84 33 11 60 87 80 7 88 94 52 \n",
            "M sorted 14: \n",
            "dim: 32768 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 15: \n",
            "dim: 65536 \n",
            "7 74 21 4 21 56 45 10 58 79  ... 77 20 50 51 29 34 68 23 18 0 \n",
            "M sorted 15: \n",
            "dim: 65536 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 16: \n",
            "dim: 131072 \n",
            "75 97 49 36 41 20 10 90 23 7  ... 99 91 88 73 85 43 82 16 1 7 \n",
            "M sorted 16: \n",
            "dim: 131072 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 17: \n",
            "dim: 262144 \n",
            "2 16 34 96 22 40 21 56 59 73  ... 25 90 27 83 87 73 54 12 66 38 \n",
            "M sorted 17: \n",
            "dim: 262144 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 18: \n",
            "dim: 524288 \n",
            "45 78 46 21 30 52 52 18 71 46  ... 83 88 5 31 76 5 46 84 18 79 \n",
            "M sorted 18: \n",
            "dim: 524288 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "M 19: \n",
            "dim: 1000000 \n",
            "69 21 44 14 2 20 92 88 72 0  ... 13 27 40 30 3 26 94 48 74 70 \n",
            "M sorted 19: \n",
            "dim: 1000000 \n",
            "-1 0 0 0 0 0 0 0 0 0  ... 99 99 99 99 99 99 99 99 99 99 \n",
            "\n",
            "Execution time with N = 2: 0.448736 ms\n",
            "Execution time with N = 4: 0.761856 ms\n",
            "Execution time with N = 8: 1.613344 ms\n",
            "Execution time with N = 16: 3.441632 ms\n",
            "Execution time with N = 32: 7.161504 ms\n",
            "Execution time with N = 64: 14.460576 ms\n",
            "Execution time with N = 128: 35.400448 ms\n",
            "Execution time with N = 256: 58.008865 ms\n",
            "Execution time with N = 512: 121.128319 ms\n",
            "Execution time with N = 1024: 226.676163 ms\n",
            "Execution time with N = 2048: 453.185699 ms\n",
            "Execution time with N = 4096: 884.922485 ms\n",
            "Execution time with N = 8192: 1779.197266 ms\n",
            "Execution time with N = 16384: 3545.820068 ms\n",
            "Execution time with N = 32768: 7064.751465 ms\n",
            "Execution time with N = 65536: 14106.861328 ms\n",
            "Execution time with N = 131072: 28279.513672 ms\n",
            "Execution time with N = 262144: 56488.234375 ms\n",
            "Execution time with N = 524288: 112941.757812 ms\n",
            "Execution time with N = 1000000: 214852.593750 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfeMLwvqiHUO"
      },
      "source": [
        "# Question 2.4 : BATCH MERGE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v0O9-XzSijyT",
        "outputId": "2c16957f-0d1e-4496-9309-336cd12f434a"
      },
      "source": [
        "%%cuda --name main.cu\n",
        "/* In this part, we assume we have a large NUMBER N(>= 10^3) of arrays {A_i}(1<=i<=N) and {B_i}(1<=i<=N)\n",
        "with |A_i|+|B_i|<=1024 for each i. Using some changes on \"mergeSmall_k\" we would like to write\n",
        "\"mergeSmallBatch_k\" that merges two by two, for each i, A_i and B_i.\n",
        "Given a fixed common size d<=1024, \"mergeSmallBatch_k\" is launched using the syntax:\n",
        "  mergeSmallBatch_k<<<numBlocks, threadsPerBlock>>>(...);\n",
        "with \"threadsPerBlock\" is MULTIPLE of \"d\" but smaller than 1024\n",
        "and \"numBlocks\" is an arbirtrary sufficiently big number.\n",
        "(1) Explain why the indices:\n",
        "- int tidx = threadIdx.x%d;\n",
        "    \"tidx\": since if d<=512 (1024/2 = 512 minimum multiple) we can mergesort more than one array\n",
        "            per block (exactly m arrays: m = 1024/d). \"tidx\" allows us to enumerate from 1 to d, the elements of each of pair {A_i},{B_i} with (1<=i<=m) in the block.\n",
        "- int Qt = (threadIdx.x-tidx)/d;\n",
        "    \"Qt\": local numeration of arrays in a block. \"Qt\" goes from 1 to m\n",
        "- gbx = Qt + blockIdx.x * (blockDim.x/d);\n",
        "    \"gbx\": global numeration of arrays. \"gbx\" goes from 1 to N\n",
        "are important in the definition of \"mergeSmallBatch_k\"\n",
        "(2) Write the kernel \"mergeSmallBatch_k\" that batch merges two by two {A_i} and {B_i} (1<=i<=N)\n",
        "Give the execution time with respect to d = 4,8,...,1024 */\n",
        "\n",
        "//NTPB => Number of threads per block is a multiple of d !!!\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include\"repos/functions/functions.hpp\"\n",
        "#include<algorithm>\n",
        "#include<fstream> //to export data\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "#define N 5 // number of arrays\n",
        "\n",
        "//############################### KERNEL ##################################\n",
        "__global__ void mergeSmallBatch_k(int **A, int *dim_A, int **B, int *dim_B, int **M, int d){\n",
        "  int tidx = threadIdx.x % d; //enumeration of elements each array of the block -> 0 : d-1\n",
        "  int Qt = (threadIdx.x-tidx)/d; //enumeration of the arrays in the block -> 0 : m-1\n",
        "  int gbx = Qt + blockIdx.x * (blockDim.x/d); //global enumeration of arrays -> 0 : N-1\n",
        "\n",
        "  //int idx = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "  if(gbx < N){\n",
        "    if(tidx>dim_A[gbx]){\n",
        "      K_x = tidx - dim_A[gbx]; //(K_x, K_y): low point of diagonal\n",
        "      K_y = dim_A[gbx];\n",
        "      P_x = dim_A[gbx]; //(P_x,P_y): high point of diagonal\n",
        "      P_y = tidx - dim_A[gbx];\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = tidx;\n",
        "      P_x = tidx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2); //integer\n",
        "      //distance on y == distance on x, because diagonal\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      //offset is an \"int\" (integer), so it's rounded to the smaller integer -> Q will be closer to K\n",
        "      if (Q_y>=0 && Q_x<=dim_B[gbx] && (Q_y == dim_A[gbx] || Q_x==0 || A[gbx][Q_y] > B[gbx][Q_x-1]) ){\n",
        "        // (Q_y>=0 and Q_x<=B) -> Q is in the grid\n",
        "        // Q_y=|A| -> Q is on the down border\n",
        "        // Q_x=0   -> Q is on the left border\n",
        "        // A[Q_y>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if (Q_x == dim_B[gbx] || Q_y == 0 || A[gbx][Q_y-1] <= B[gbx][Q_x]){\n",
        "            // Q_x=|B| -> Q is on the right border\n",
        "            // Q_y=0   -> Q in on the up border\n",
        "            // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q'\n",
        "              if (Q_y<dim_A[gbx] && (Q_x == dim_B[gbx] || A[gbx][Q_y]<= B[gbx][Q_x]) )\n",
        "              //if Q is not on the down border (= if the \"path\" can go down) and it MUST go down\n",
        "                M[gbx][tidx] = A[gbx][Q_y]; //the \"path\" goes down (in A direction)\n",
        "              else //if it can't go down\n",
        "                M[gbx][tidx] = B[gbx][Q_x]; //the \"path\" goes right (in B direction)s\n",
        "\n",
        "              break;\n",
        "          }else{ //if the path is over Q but not under Q\n",
        "              K_x = Q_x + 1; //move Q up by moving K up (updating Q_x to remain on diagonal)\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{ //if the path is under Q\n",
        "        P_x = Q_x - 1; //move Q down by moving P down (updating Q_x to remain on diagonal)\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "//############################### WRAPPER ##################################\n",
        "void wrapper(int **A, int *dim_A, int **B, int *dim_B, int **M, int dd){\n",
        "  //A, B, M: array of N array -> A[i]: array of N elements\n",
        "  //dim_A, dim_B: array of N integers -> dim_A[i]: dimension of A_i\n",
        "  int **A_GPU, **B_GPU, **M_GPU;\n",
        "  int *dim_A_GPU, *dim_B_GPU;\n",
        "\n",
        "  int count;\n",
        "  cudaDeviceProp prop;\n",
        "  testCUDA(cudaGetDeviceCount(&count));\n",
        "  testCUDA(cudaGetDeviceProperties(&prop, count-1));\n",
        "\n",
        "\n",
        "  //########## INITIALIZATION ##########\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  testCUDA(cudaMalloc(&dim_A_GPU, N*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&dim_B_GPU, N*sizeof(int)));\n",
        "  testCUDA(cudaMemcpy(dim_A_GPU, dim_A, N*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(dim_B_GPU, dim_B, N*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  /*Procedure to allocate on the DEVICE an array of arrays:\n",
        "  (1)Allocate the POINTERS to a HOST memory\n",
        "  (2)Allocate DEVICE memory for EACH ARRAY and store its pointer in the host memory\n",
        "  (3)Allocate DEVICE memory for storing the pointers\n",
        "  (4)Then copy the host memory to the device memory */\n",
        "\n",
        "  //(1) Allocate the ARRAY of POINTERS to HOST memory\n",
        "    // in order to store \"A\", \"B\", \"M\" into \"A_GPU\", \"B_GPU\", \"M_GPU\"\n",
        "    int ** A_host= (int**)malloc(N*sizeof(int *));\n",
        "    int ** B_host = (int**)malloc(N*sizeof(int *));\n",
        "    int ** M_host = (int**)malloc(N*sizeof(int *));\n",
        "    // in order to copy from \"M_ GPU\" to \"M\"\n",
        "    int ** M_host_pointers = (int**)malloc(N*sizeof(int *));//It is Necessary to keep a copy of the pointers in the host, in order to use cudaMemcpy -> cudaMemcpy(Pointer on CPU of a GPU object, pointer on CPU of a CPU object)\n",
        "\n",
        "  //(2) Allocate DEVICE memory for EACH ARRAY and store its pointer in the host memory\n",
        "    for(int i=0; i<N; ++i){\n",
        "      testCUDA(cudaMalloc(&A_host[i], dim_A[i]*sizeof(int)));\n",
        "      testCUDA(cudaMalloc(&B_host[i], dim_B[i]*sizeof(int)));\n",
        "      testCUDA(cudaMalloc(&M_host[i], dd*sizeof(int)));\n",
        "      M_host_pointers[i] = M_host[i]; //I keep in the host a copy of the pointers\n",
        "    }\n",
        "    for(int i=0; i<N; ++i){\n",
        "      testCUDA(cudaMemcpy(A_host[i], A[i], dim_A[i]*sizeof(int), cudaMemcpyHostToDevice));\n",
        "      testCUDA(cudaMemcpy(B_host[i], B[i], dim_B[i]*sizeof(int), cudaMemcpyHostToDevice));\n",
        "    }\n",
        "\n",
        "  //(3)Allocate DEVICE memory for storing the pointers\n",
        "    testCUDA(cudaMalloc(&A_GPU, N*sizeof(int *)));\n",
        "    testCUDA(cudaMalloc(&B_GPU, N*sizeof(int *)));\n",
        "    testCUDA(cudaMalloc(&M_GPU, N*sizeof(int *)));\n",
        "\n",
        "  //(4)Then copy the host memory to the device memory\n",
        "    testCUDA(cudaMemcpy(A_GPU, A_host, N*sizeof(int *), cudaMemcpyHostToDevice));\n",
        "    testCUDA(cudaMemcpy(B_GPU, B_host, N*sizeof(int *), cudaMemcpyHostToDevice));\n",
        "    testCUDA(cudaMemcpy(M_GPU, M_host, N*sizeof(int *), cudaMemcpyHostToDevice));\n",
        "\n",
        "\n",
        "  //########## CALLING THE KERNEL ##########\n",
        "  printf(\"N: %i, d: %i \\n\",N, dd);\n",
        "  int m = min(1024 / dd, N); //number of pair of arrays that each block can merge\n",
        "  printf(\"Number of pair of arrays that each block merge: %i \\n\", m);\n",
        "  int NB;// number of blocks needed\n",
        "  if(N%m == 0)\n",
        "    NB = N/m;\n",
        "  else\n",
        "    NB = N/m + 1;\n",
        "  printf(\"Max number of blocks available: %li \\n\",prop.maxGridSize[0] );\n",
        "  printf(\"Max number of block required: %li \\n\", NB );\n",
        "  printf(\"Number of thread per block: %li \\n\", dd*m);\n",
        "  if( NB < prop.maxGridSize[0]){\n",
        "    printf(\"No need for a while loop \\n\" );\n",
        "    mergeSmallBatch_k<<<NB,dd*m>>>(A_GPU, dim_A_GPU, B_GPU, dim_B_GPU, M_GPU, dd);\n",
        "  } else{\n",
        "    printf(\"while loop is needed \\n \");\n",
        "    //Number of blocks: a number smaller than NB_MAX. I chose: NB == NTPB\n",
        "    mergeSmallBatch_k<<<dd*m,dd*m>>>(A_GPU, dim_A_GPU, B_GPU, dim_B_GPU, M_GPU, dd);\n",
        "  }\n",
        "\n",
        "//Copying \"M_GPU\" into \"M\", thanks to the HOST pointers in \"M_host_pointers\"\n",
        " for(int i=0; i<N; ++i){\n",
        "    testCUDA(cudaMemcpy(M[i], M_host_pointers[i], dd*sizeof(int), cudaMemcpyDeviceToHost));   //???\n",
        "  }\n",
        "\n",
        "\n",
        "  //##### FREE MEMORY & GET EXECUTION TIME #####\n",
        "  for(int i=0; i<N; ++i){\n",
        "    testCUDA(cudaFree(A_host[i]));\n",
        "    testCUDA(cudaFree(B_host[i]));\n",
        "    testCUDA(cudaFree(M_host[i]));\n",
        "  }\n",
        "\n",
        "  free(A_host);\n",
        "  free(B_host);\n",
        "  free(M_host);\n",
        "  free(M_host_pointers);\n",
        "\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(dim_A_GPU));\n",
        "  testCUDA(cudaFree(dim_B_GPU));\n",
        "\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  printf(\"Execution time: %f ms\\n \\n\", TimerV);\n",
        "\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  //#####  INITIALIZATION  #####\n",
        " int d = 6;// 6 elements in each 5 arrays mergesorted in M\n",
        "\n",
        "  int **A, **B, **M; // int **\n",
        "  int *dim_A, *dim_B;\n",
        "  A = (int**)malloc(N*sizeof(int *));\n",
        "  B = (int**)malloc(N*sizeof(int *));\n",
        "  M = (int**)malloc(N*sizeof(int *));\n",
        "  dim_A = (int*)malloc(N*sizeof(int));\n",
        "  dim_B = (int*)malloc(N*sizeof(int));\n",
        "\n",
        "  srand (time(NULL));\n",
        "  for(int i=0; i<N; ++i){\n",
        "      dim_A[i] = rand() % d;\n",
        "    dim_B[i] = d - dim_A[i];\n",
        "    if(dim_A[i]<dim_B[i]){\n",
        "      std::swap(dim_A[i],dim_B[i]);\n",
        "      std::swap(A[i],B[i]);\n",
        "    }\n",
        "    A[i] = (int*)malloc(dim_A[i]*sizeof(int));\n",
        "    B[i] = (int*)malloc(dim_B[i]*sizeof(int));\n",
        "    M[i] = (int*)malloc(d*sizeof(int));\n",
        "    generate_random(A[i],dim_A[i],0,100);\n",
        "    mergesort(A[i],0,dim_A[i]-1);\n",
        "    generate_random(B[i],dim_B[i],0,100);\n",
        "    mergesort(B[i],0,dim_B[i]-1);\n",
        "  }\n",
        "\n",
        "  printf(\"A\\n\");\n",
        "  for(int i=0; i<N; ++i){\n",
        "    printt_array(A[i],dim_A[i]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  printf(\"B\\n\");\n",
        "  for(int i=0; i<N; ++i){\n",
        "    printt_array(B[i],dim_B[i]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "//######## WRAPPER CALL #########\n",
        "  wrapper(A, dim_A, B, dim_B, M, d);\n",
        "\n",
        "\n",
        "  printf(\"M\\n\");\n",
        "  for(int i=0; i<N; ++i){\n",
        "    printt_array(M[i],d);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "//####### FREE THE MEMORY #######\n",
        "  for(int i=0; i<N; ++i){\n",
        "    free(A[i]);\n",
        "    free(B[i]);\n",
        "    free(M[i]);\n",
        "  }\n",
        "\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(M);\n",
        "  free(dim_A);\n",
        "  free(dim_B);\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1_wLkBGjpP7",
        "outputId": "e480c2ad-c93d-4446-acdc-6887ba4afc87"
      },
      "source": [
        "!cd src && make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(40): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "\u001b[01m\u001b[Kmain.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid wrapper(int**, int*, int**, int*, int**, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmain.cu:160:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Max number of blocks available: %li \\n\"\u001b[32m\u001b[K,prop.maxGridSize[0] \u001b[m\u001b[K\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                  \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cu:161:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Max number of block required: %li \\n\", \u001b[01;35m\u001b[KN\u001b[m\u001b[KB );\n",
            "                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cu:162:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Number of thread per block: %li \\n\"\u001b[32m\u001b[K, dd*m\u001b[m\u001b[K\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                              \u001b[32m\u001b[K~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbEJhbfnjuNK",
        "outputId": "81bab321-681e-4fef-831e-72c2379a9465"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "A\n",
            "36 74 80 93 \n",
            "\n",
            "1 6 9 29 97 \n",
            "\n",
            "26 34 47 84 88 \n",
            "\n",
            "25 47 48 50 75 96 \n",
            "\n",
            "50 56 65 87 \n",
            "\n",
            "B\n",
            "9 91 \n",
            "\n",
            "33 \n",
            "\n",
            "51 \n",
            "\n",
            "\n",
            "\n",
            "10 88 \n",
            "\n",
            "N: 5, d: 6 \n",
            "Number of pair of arrays that each block merge: 5 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 1 \n",
            "Number of thread per block: 30 \n",
            "No need for a while loop \n",
            "Execution time: 0.674880 ms\n",
            " \n",
            "M\n",
            "9 36 74 80 91 93 \n",
            "\n",
            "1 6 9 29 33 97 \n",
            "\n",
            "26 34 47 51 84 88 \n",
            "\n",
            "25 47 48 50 75 96 \n",
            "\n",
            "10 50 56 65 87 88 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raN6ubIolqgF"
      },
      "source": [
        "# Question 2.5 : BATCH MERGE Execution time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "98cI8EI-jzz3",
        "outputId": "7d0142d9-f0f9-4025-8aba-4f8c3d50f078"
      },
      "source": [
        "%%cuda --name main.cu\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include\"repos/functions/functions.hpp\"\n",
        "#include<algorithm>\n",
        "#include<fstream> //to export data\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "#define N 1000000\n",
        "\n",
        "//############################### KERNEL ##################################\n",
        "__global__ void mergeSmallBatch_k(int **A, int *dim_A, int **B, int *dim_B, int **M, int d){\n",
        "  int tidx = threadIdx.x % d; //enumeration of elements each array of the block -> 0 : d-1\n",
        "  int Qt = (threadIdx.x-tidx)/d; //enumeration of the arrays in the block -> 0 : m-1\n",
        "  int gbx = Qt + blockIdx.x * (blockDim.x/d); //global enumeration of arrays -> 0 : N-1\n",
        "\n",
        "  //int idx = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "  if(gbx < N){\n",
        "    if(tidx>dim_A[gbx]){\n",
        "      K_x = tidx - dim_A[gbx]; //(K_x, K_y): low point of diagonal\n",
        "      K_y = dim_A[gbx];\n",
        "      P_x = dim_A[gbx]; //(P_x,P_y): high point of diagonal\n",
        "      P_y = tidx - dim_A[gbx];\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = tidx;\n",
        "      P_x = tidx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2); //integer\n",
        "      //distance on y == distance on x, because diagonal\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      //offset is an \"int\" (integer), so it's rounded to the smaller integer -> Q will be closer to K\n",
        "      if (Q_y>=0 && Q_x<=dim_B[gbx] && (Q_y == dim_A[gbx] || Q_x==0 || A[gbx][Q_y] > B[gbx][Q_x-1]) ){\n",
        "        // (Q_y>=0 and Q_x<=B) -> Q is in the grid\n",
        "        // Q_y=|A| -> Q is on the down border\n",
        "        // Q_x=0   -> Q is on the left border\n",
        "        // A[Q_y>B[Q_x-1] -> the \"path\" goes 'over Q' or 'pass through Q'\n",
        "          if (Q_x == dim_B[gbx] || Q_y == 0 || A[gbx][Q_y-1] <= B[gbx][Q_x]){\n",
        "            // Q_x=|B| -> Q is on the right border\n",
        "            // Q_y=0   -> Q in on the up border\n",
        "            // A[Q_y-1]<=B[Q_x] -> the \"path\" goes 'under Q' or 'pass through Q'\n",
        "              if (Q_y<dim_A[gbx] && (Q_x == dim_B[gbx] || A[gbx][Q_y]<= B[gbx][Q_x]) )\n",
        "              //if Q is not on the down border (= if the \"path\" can go down) and it MUST go down\n",
        "                M[gbx][tidx] = A[gbx][Q_y]; //the \"path\" goes down (in A direction)\n",
        "              else //if it can't go down\n",
        "                M[gbx][tidx] = B[gbx][Q_x]; //the \"path\" goes right (in B direction)s\n",
        "\n",
        "              break;\n",
        "          }else{ //if the path is over Q but not under Q\n",
        "              K_x = Q_x + 1; //move Q up by moving K up (updating Q_x to remain on diagonal)\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{ //if the path is under Q\n",
        "        P_x = Q_x - 1; //move Q down by moving P down (updating Q_x to remain on diagonal)\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "//############################### WRAPPER ##################################\n",
        "void wrapper(int **A, int *dim_A, int **B, int *dim_B, int **M, int dd, float *duration, int k){\n",
        "  //A, B, M: array of N array -> A[i]: array of N elements\n",
        "  //dim_A, dim_B: array of N integers -> dim_A[i]: dimension of A_i\n",
        "  int **A_GPU, **B_GPU, **M_GPU;\n",
        "  int *dim_A_GPU, *dim_B_GPU;\n",
        "\n",
        "  int count;\n",
        "  cudaDeviceProp prop;\n",
        "  testCUDA(cudaGetDeviceCount(&count));\n",
        "  testCUDA(cudaGetDeviceProperties(&prop, count-1));\n",
        "\n",
        "\n",
        "  //########## INITIALIZATION ##########\n",
        "  float TimerV;\n",
        "  cudaEvent_t start, stop;\n",
        "  testCUDA(cudaEventCreate(&start));\n",
        "  testCUDA(cudaEventCreate(&stop));\n",
        "  testCUDA(cudaEventRecord(start,0));\n",
        "\n",
        "  testCUDA(cudaMalloc(&dim_A_GPU, N*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&dim_B_GPU, N*sizeof(int)));\n",
        "  testCUDA(cudaMemcpy(dim_A_GPU, dim_A, N*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(dim_B_GPU, dim_B, N*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  /*Procedure to allocate on the DEVICE an array of arrays:\n",
        "  (1)Allocate the POINTERS to a HOST memory\n",
        "  (2)Allocate DEVICE memory for EACH ARRAY and store its pointer in the host memory\n",
        "  (3)Allocate DEVICE memory for storing the pointers\n",
        "  (4)Then copy the host memory to the device memory */\n",
        "\n",
        "  //(1) Allocate the ARRAY of POINTERS to HOST memory\n",
        "    // in order to store \"A\", \"B\", \"M\" into \"A_GPU\", \"B_GPU\", \"M_GPU\"\n",
        "    int ** A_host= (int**)malloc(N*sizeof(int *));\n",
        "    int ** B_host = (int**)malloc(N*sizeof(int *));\n",
        "    int ** M_host = (int**)malloc(N*sizeof(int *));\n",
        "    // in order to copy from \"M_ GPU\" to \"M\"\n",
        "    int ** M_host_pointers = (int**)malloc(N*sizeof(int *));//It is Necessary to keep a copy of the pointers in the host, in order to use cudaMemcpy -> cudaMemcpy(Pointer on CPU of a GPU object, pointer on CPU of a CPU object)\n",
        "\n",
        "  //(2) Allocate DEVICE memory for EACH ARRAY and store its pointer in the host memory\n",
        "    for(int i=0; i<N; ++i){\n",
        "      testCUDA(cudaMalloc(&A_host[i], dim_A[i]*sizeof(int)));\n",
        "      testCUDA(cudaMalloc(&B_host[i], dim_B[i]*sizeof(int)));\n",
        "      testCUDA(cudaMalloc(&M_host[i], dd*sizeof(int)));\n",
        "      M_host_pointers[i] = M_host[i]; //I keep in the host a copy of the pointers\n",
        "    }\n",
        "    for(int i=0; i<N; ++i){\n",
        "      testCUDA(cudaMemcpy(A_host[i], A[i], dim_A[i]*sizeof(int), cudaMemcpyHostToDevice));\n",
        "      testCUDA(cudaMemcpy(B_host[i], B[i], dim_B[i]*sizeof(int), cudaMemcpyHostToDevice));\n",
        "    }\n",
        "\n",
        "  //(3)Allocate DEVICE memory for storing the pointers\n",
        "    testCUDA(cudaMalloc(&A_GPU, N*sizeof(int *)));\n",
        "    testCUDA(cudaMalloc(&B_GPU, N*sizeof(int *)));\n",
        "    testCUDA(cudaMalloc(&M_GPU, N*sizeof(int *)));\n",
        "\n",
        "  //(4)Then copy the host memory to the device memory\n",
        "    testCUDA(cudaMemcpy(A_GPU, A_host, N*sizeof(int *), cudaMemcpyHostToDevice));\n",
        "    testCUDA(cudaMemcpy(B_GPU, B_host, N*sizeof(int *), cudaMemcpyHostToDevice));\n",
        "    testCUDA(cudaMemcpy(M_GPU, M_host, N*sizeof(int *), cudaMemcpyHostToDevice));\n",
        "\n",
        "\n",
        "  //########## CALLING THE KERNEL ##########\n",
        "  printf(\"N: %i, d: %i \\n\",N, dd);\n",
        "  int m = min(1024 / dd, N); //number of pair of arrays that each block can merge\n",
        "  printf(\"Number of pair of arrays that each block merge: %i \\n\", m);\n",
        "  int NB;// number of blocks needed\n",
        "  if(N%m == 0)\n",
        "    NB = N/m;\n",
        "  else\n",
        "    NB = N/m + 1;\n",
        "  printf(\"Max number of blocks available: %li \\n\",prop.maxGridSize[0] );\n",
        "  printf(\"Max number of block required: %li \\n\", NB );\n",
        "  printf(\"Number of thread per block: %li \\n\", dd*m);\n",
        "  if( NB < prop.maxGridSize[0]){\n",
        "    printf(\"No need for a while loop \\n\" );\n",
        "    mergeSmallBatch_k<<<NB,dd*m>>>(A_GPU, dim_A_GPU, B_GPU, dim_B_GPU, M_GPU, dd);\n",
        "  } else{\n",
        "    printf(\"while loop is needed \\n \");\n",
        "    //Number of blocks: a number smaller than NB_MAX. I chose: NB == NTPB\n",
        "    mergeSmallBatch_k<<<dd*m,dd*m>>>(A_GPU, dim_A_GPU, B_GPU, dim_B_GPU, M_GPU, dd);\n",
        "  }\n",
        "\n",
        "//Copying \"M_GPU\" into \"M\", thanks to the HOST pointers in \"M_host_pointers\"\n",
        " for(int i=0; i<N; ++i){\n",
        "    testCUDA(cudaMemcpy(M[i], M_host_pointers[i], dd*sizeof(int), cudaMemcpyDeviceToHost));   //???\n",
        "  }\n",
        "\n",
        "\n",
        "  //##### FREE MEMORY & GET EXECUTION TIME #####\n",
        "  for(int i=0; i<N; ++i){\n",
        "    testCUDA(cudaFree(A_host[i]));\n",
        "    testCUDA(cudaFree(B_host[i]));\n",
        "    testCUDA(cudaFree(M_host[i]));\n",
        "  }\n",
        "\n",
        "  free(A_host);\n",
        "  free(B_host);\n",
        "  free(M_host);\n",
        "  free(M_host_pointers);\n",
        "\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(dim_A_GPU));\n",
        "  testCUDA(cudaFree(dim_B_GPU));\n",
        "\n",
        "  testCUDA(cudaEventRecord(stop,0));\n",
        "  testCUDA(cudaEventSynchronize(stop));\n",
        "  testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "  printf(\"Execution time: %f ms\\n \\n\", TimerV);\n",
        "  duration[k] = TimerV;\n",
        "\n",
        "  testCUDA(cudaEventDestroy(start));\n",
        "  testCUDA(cudaEventDestroy(stop));\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  //#####  INITIALIZATION  #####\n",
        " int d[9];\n",
        " float duration[9];\n",
        "  for(int i=0; i<9; ++i){\n",
        "    d[i] = pow(2,i+2);\n",
        "}\n",
        "\n",
        "  int **A, **B, **M; // int **\n",
        "  int *dim_A, *dim_B;\n",
        "  A = (int**)malloc(N*sizeof(int *));\n",
        "  B = (int**)malloc(N*sizeof(int *));\n",
        "  M = (int**)malloc(N*sizeof(int *));\n",
        "  dim_A = (int*)malloc(N*sizeof(int));\n",
        "  dim_B = (int*)malloc(N*sizeof(int));\n",
        "\n",
        "for(int k=0; k<9; ++k){\n",
        "  srand (time(NULL));\n",
        "  for(int i=0; i<N; ++i){\n",
        "      dim_A[i] = rand() % d[k];\n",
        "    dim_B[i] = d[k] - dim_A[i];\n",
        "    if(dim_A[i]<dim_B[i]){\n",
        "      std::swap(dim_A[i],dim_B[i]);\n",
        "      std::swap(A[i],B[i]);\n",
        "    }\n",
        "    A[i] = (int*)malloc(dim_A[i]*sizeof(int));\n",
        "    B[i] = (int*)malloc(dim_B[i]*sizeof(int));\n",
        "    M[i] = (int*)malloc(d[k]*sizeof(int));\n",
        "  //  M[i] = (int*)malloc(d*sizeof(int));\n",
        "    generate_random(A[i],dim_A[i],0,100);\n",
        "    mergesort(A[i],0,dim_A[i]-1);\n",
        "    generate_random(B[i],dim_B[i],0,100);\n",
        "    mergesort(B[i],0,dim_B[i]-1);\n",
        "  }\n",
        "\n",
        "/*\n",
        "  printf(\"A\\n\");\n",
        "  for(int i=0; i<N; ++i){\n",
        "    print_array(A[i],dim_A[i]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "  printf(\"B\\n\");\n",
        "  for(int i=0; i<N; ++i){\n",
        "    print_array(B[i],dim_B[i]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "*/\n",
        "\n",
        "//######## WRAPPER CALL #########\n",
        "  wrapper(A, dim_A, B, dim_B, M, d[k], duration, k);\n",
        "\n",
        "\n",
        "/*\n",
        "  printf(\"M\\n\");\n",
        "  for(int i=0; i<N; ++i){\n",
        "    print_array(M[i],d[k]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "  */\n",
        "\n",
        "\n",
        "\n",
        "//####### FREE THE MEMORY #######\n",
        "  for(int i=0; i<N; ++i){\n",
        "    free(A[i]);\n",
        "    free(B[i]);\n",
        "    free(M[i]);\n",
        "  }\n",
        "\n",
        "}\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(M);\n",
        "  free(dim_A);\n",
        "  free(dim_B);\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBFirBLTk0Ks",
        "outputId": "c08333ae-11ec-4e86-b9fa-0bf245995aa1"
      },
      "source": [
        "!cd src && make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(19): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "\u001b[01m\u001b[Kmain.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid wrapper(int**, int*, int**, int*, int**, int, float*, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmain.cu:139:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Max number of blocks available: %li \\n\"\u001b[32m\u001b[K,prop.maxGridSize[0] \u001b[m\u001b[K\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                  \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cu:140:50:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Max number of block required: %li \\n\", \u001b[01;35m\u001b[KN\u001b[m\u001b[KB );\n",
            "                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cu:141:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%li\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "   printf(\"Number of thread per block: %li \\n\"\u001b[32m\u001b[K, dd*m\u001b[m\u001b[K\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                              \u001b[32m\u001b[K~~~~~~\u001b[m\u001b[K\u001b[01;35m\u001b[K^\u001b[m\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhy9Zni8lNFX",
        "outputId": "36855e48-781d-4545-9405-d6f6c25188de"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "N: 1000000, d: 4 \n",
            "Number of pair of arrays that each block merge: 256 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 3907 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 69196.890625 ms\n",
            " \n",
            "N: 1000000, d: 8 \n",
            "Number of pair of arrays that each block merge: 128 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 7813 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 70698.835938 ms\n",
            " \n",
            "N: 1000000, d: 16 \n",
            "Number of pair of arrays that each block merge: 64 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 15625 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 72707.054688 ms\n",
            " \n",
            "N: 1000000, d: 32 \n",
            "Number of pair of arrays that each block merge: 32 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 31250 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 74941.726562 ms\n",
            " \n",
            "N: 1000000, d: 64 \n",
            "Number of pair of arrays that each block merge: 16 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 62500 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 77866.078125 ms\n",
            " \n",
            "N: 1000000, d: 128 \n",
            "Number of pair of arrays that each block merge: 8 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 125000 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 79305.085938 ms\n",
            " \n",
            "N: 1000000, d: 256 \n",
            "Number of pair of arrays that each block merge: 4 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 250000 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 75415.070312 ms\n",
            " \n",
            "N: 1000000, d: 512 \n",
            "Number of pair of arrays that each block merge: 2 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 500000 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 74090.031250 ms\n",
            " \n",
            "N: 1000000, d: 1024 \n",
            "Number of pair of arrays that each block merge: 1 \n",
            "Max number of blocks available: 2147483647 \n",
            "Max number of block required: 1000000 \n",
            "Number of thread per block: 1024 \n",
            "No need for a while loop \n",
            "Execution time: 74890.578125 ms\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn7zsKpMb14O"
      },
      "source": [
        "# Application with Alice and Bob => Cryptography "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iCMQ-I8Ab4bg",
        "outputId": "e4198af4-630e-46aa-fa82-0f689b3c0fd7"
      },
      "source": [
        "%%cuda --name main.cu \n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<cassert>\n",
        "#include<time.h>\n",
        "#include\"repos/functions/functions.hpp\"\n",
        "#include<algorithm>\n",
        "#include <iostream> \n",
        "#include<fstream> //to export data\n",
        "#define testCUDA(error) (testCUDA(error,__FILE__,__LINE__))\n",
        "\n",
        "// -----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "// ----------------------------------------------------- MERGE ALGOS -----------------------------------------------------------------------------------------------\n",
        "// -----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#define NSM 4096\n",
        "#define Z 32\n",
        "\n",
        "//#################### KERNEL - find MERGE PATH in the PARTITION POINTS ##############################\n",
        "__global__ void MergePath_partition(int *A_gpu, int dim_A, int *B_gpu, int dim_B, int *X_gpu, int *Y_gpu){\n",
        "  int idx = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A+dim_B);\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        "    if(idx>dim_A){\n",
        "      K_x = idx - dim_A;\n",
        "      K_y = dim_A;\n",
        "      P_x = dim_A;\n",
        "      P_y = idx - dim_A;\n",
        "    }else{\n",
        "      K_x = 0;\n",
        "      K_y = idx;\n",
        "      P_x = idx;\n",
        "      P_y = 0;\n",
        "    }\n",
        "    while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);//integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if (Q_y>=0 && Q_x<=dim_B && (Q_y == dim_A || Q_x==0 || A_gpu[Q_y] > B_gpu[Q_x-1]) ){\n",
        "          if (Q_x == dim_B || Q_y == 0 || A_gpu[Q_y-1] <= B_gpu[Q_x]){\n",
        "                X_gpu[idx] = Q_x;\n",
        "                Y_gpu[idx] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "  if(blockIdx.x==0 && threadIdx.x==0){\n",
        "    X_gpu[dim_A+dim_B] = dim_B;\n",
        "    Y_gpu[dim_A+dim_B] = dim_A;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "//######################### KERNEL - BIG PATH #################################\n",
        "__global__ void pathBig_k(int *X_gpu, int *Y_gpu, const int *A_gpu, const int *B_gpu, int dim_A, int dim_B){\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  __shared__ int A_sh[Z], B_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "  int K_x, K_y, P_x, P_y, Q_x, Q_y;\n",
        "  int off_set;\n",
        "\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "  if(idx_sh + y_start < dim_A)\n",
        "    A_sh[idx_sh] = A_gpu[idx_sh + y_start];\n",
        "  if(idx_sh + x_start< dim_B)\n",
        "    B_sh[idx_sh] = B_gpu[idx_sh + x_start];\n",
        "    if(idx_sh + y_start + 1 > dim_A){\n",
        "      K_x = x_start + (idx_sh + y_start + 1 - dim_A);\n",
        "      K_y = dim_A;\n",
        "      } else{\n",
        "        K_x = x_start;\n",
        "        K_y = idx_sh + y_start + 1;\n",
        "        }\n",
        "    if(idx_sh + x_start + 1 > dim_B){\n",
        "      P_x = dim_B;\n",
        "      P_y = y_start + (idx_sh + x_start + 1 - dim_B);\n",
        "      } else{\n",
        "        P_x = idx_sh + x_start + 1;\n",
        "        P_y = y_start;\n",
        "      }\n",
        "\n",
        "      while(1){\n",
        "      off_set = (abs(K_y-P_y)/2);//integer\n",
        "      Q_x = K_x + off_set;\n",
        "      Q_y = K_y - off_set;\n",
        "      if ((Q_y>=y_start && Q_y>=0) && (Q_x<=(Z+x_start)<=dim_B) && ((Q_y == (Z+y_start) || Q_y == dim_A) || (Q_x==x_start || Q_x==0) || A_sh[Q_y - y_start] > B_sh[Q_x -1 - x_start]) ){\n",
        "          if ((Q_x == (Z+x_start) || Q_x == dim_B) || (Q_y == y_start || Q_y == 0) || A_sh[Q_y -1 - y_start] <= B_sh[Q_x - x_start]){\n",
        "                X_gpu[idx_start + idx_sh +1] = Q_x;\n",
        "                Y_gpu[idx_start + idx_sh +1] = Q_y;\n",
        "                break;\n",
        "          }else{\n",
        "              K_x = Q_x + 1;\n",
        "              K_y = Q_y - 1;\n",
        "          }\n",
        "      }else{\n",
        "        P_x = Q_x - 1;\n",
        "        P_y = Q_y + 1;\n",
        "      }\n",
        "    }\n",
        "    x_start = X_gpu[idx_start + Z];\n",
        "    y_start = Y_gpu[idx_start + Z];\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "\n",
        "//######################### KERNEL to MERGE  ##################################\n",
        "__global__ void mergeBig_k(int *X_gpu, int *Y_gpu, int *A_gpu, int *B_gpu, int *M_gpu, int dim_A, int dim_B){\n",
        "\n",
        "  int idx_start = min(blockIdx.x * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int idx_end = min((blockIdx.x+1) * (dim_A+dim_B) / NSM, dim_A + dim_B);\n",
        "  int x_start = X_gpu[idx_start];\n",
        "  int y_start = Y_gpu[idx_start];\n",
        "\n",
        "  __shared__ int X_sh[Z], Y_sh[Z];\n",
        "  int idx_sh = threadIdx.x;\n",
        "\n",
        " while(idx_start + idx_sh < idx_end && idx_sh < Z){\n",
        "    X_sh[idx_sh] = X_gpu[idx_start + idx_sh + 1];\n",
        "    Y_sh[idx_sh] = Y_gpu[idx_start + idx_sh + 1];\n",
        "    if(idx_sh == 0 && X_sh[0] > x_start)\n",
        "      M_gpu[idx_start] = B_gpu[x_start];\n",
        "    else if(idx_sh ==0)\n",
        "      M_gpu[idx_start] = A_gpu[y_start];\n",
        "\n",
        "    if( idx_sh>0 && X_sh[idx_sh]>X_sh[idx_sh-1])\n",
        "      M_gpu[idx_start + idx_sh] = B_gpu[X_sh[idx_sh -1]];\n",
        "    else if(idx_sh > 0)\n",
        "      M_gpu[idx_start + idx_sh] = A_gpu[Y_sh[idx_sh -1]];\n",
        "\n",
        "    x_start = X_sh[Z-1];\n",
        "    y_start = Y_sh[Z-1];\n",
        "    idx_start += Z;\n",
        "  }\n",
        "}\n",
        "//########################### WRAPPER FIND PATH ###################################\n",
        "void wrapper_FindPartition(int *a, int dim_A, int *b, int dim_B, int *m){\n",
        "  int *A_GPU, *B_GPU, *M_GPU, *X_GPU, *Y_GPU;\n",
        "\n",
        "  testCUDA(cudaMalloc(&A_GPU, dim_A*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&B_GPU, dim_B*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&X_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&Y_GPU, (dim_A+dim_B+1)*sizeof(int)));\n",
        "  testCUDA(cudaMalloc(&M_GPU, (dim_A+dim_B)*sizeof(int)));\n",
        "\n",
        "  testCUDA(cudaMemcpy(A_GPU, a, dim_A*sizeof(int), cudaMemcpyHostToDevice));\n",
        "  testCUDA(cudaMemcpy(B_GPU, b, dim_B*sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "  MergePath_partition<<<NSM,1>>>(A_GPU, dim_A, B_GPU, dim_B, X_GPU, Y_GPU);\n",
        "\n",
        "  pathBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, dim_A, dim_B);\n",
        "\n",
        "  mergeBig_k<<<NSM,Z>>>(X_GPU, Y_GPU, A_GPU, B_GPU, M_GPU, dim_A, dim_B);\n",
        "\n",
        "  testCUDA(cudaMemcpy(m, M_GPU, (dim_A+dim_B)*sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  testCUDA(cudaFree(A_GPU));\n",
        "  testCUDA(cudaFree(B_GPU));\n",
        "  testCUDA(cudaFree(M_GPU));\n",
        "  testCUDA(cudaFree(X_GPU));\n",
        "  testCUDA(cudaFree(Y_GPU));\n",
        "}\n",
        "\n",
        "//####################### PARALLEL MERGE SORT ############################\n",
        "int * merge_parallel (int *T , int p, int q, int r){\n",
        "  //A: fisrt array, B: second array, M_suport: mergesorted array\n",
        "  int *A, *B, *M_support;\n",
        "  int dim_A = q-p+1;\n",
        "  int dim_B = r-q;\n",
        "  if(dim_B > dim_A)\n",
        "    std::swap(dim_A,dim_B);\n",
        "  A = (int*)malloc(dim_A*sizeof(int));\n",
        "  B = (int*)malloc(dim_B*sizeof(int));\n",
        "  for(int i=0, j=p; i<q-p+1; ++i, ++j) //I copy in A the first array\n",
        "    A[i] = T[j];\n",
        "  for(int i=0, j=q+1; i<r-q; ++i, ++j) //I copy in B the second array\n",
        "    B[i] = T[j];\n",
        "  M_support = (int*)malloc((dim_A+dim_B)*sizeof(int));\n",
        "\n",
        "//###### WRAPPER CALL #######\n",
        "  wrapper_FindPartition(A, dim_A, B, dim_B, M_support);\n",
        "\n",
        "  for(int i=p, j=0; i<=r; ++i, ++j) //I copy the sorted array into the original one\n",
        "    T[i]=M_support[j];\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(M_support);\n",
        "  return T;\n",
        "}\n",
        "\n",
        "int * mergesort_parallel(int* T,int p,int r){\n",
        "  if(p<r){ //It stops when p == r -> if(p!=r) -> it breaks in \"SINGLETON\"\n",
        "//if(r-p<1e6)\n",
        "    int q = floor((p+r)/2); //It divides the block {p,p+1,..,r} into two sub-blocks: {p,..,q} e {q+1,..,r}\n",
        "    //I sort recursively the two sub-blocks\n",
        "    //until I get two singletons (p==r): I SORT the SINGLETONS and then I FUSION them\n",
        "    mergesort_parallel(T,p,q);\n",
        "    mergesort_parallel(T,q+1,r);\n",
        "    merge_parallel(T,p,q,r);\n",
        "  }\n",
        "  return T;\n",
        "}\n",
        "\n",
        "void parallel_sort(int* T, int N){\n",
        "  mergesort_parallel(T,0,N-1);\n",
        "}\n",
        "\n",
        "\n",
        "// #############################################################################\n",
        "// ################################ HACKAGE APP ################################\n",
        "// #############################################################################\n",
        "\n",
        "\n",
        "int EXPONENT = 65537;\n",
        "int MODULUS = 13508703;\n",
        "\n",
        "typedef int chaine;\n",
        "\n",
        "\n",
        "// ####################### EXPONENTIATION SIMPLE ###############################\n",
        "\n",
        "chaine pow(chaine a, int e)\n",
        "{\n",
        "    chaine x = a;\n",
        "    chaine x_r = 1;\n",
        " \n",
        "    while(e != 1)\n",
        "    {\n",
        "        if(e % 2)\n",
        "          x_r = x_r*x;\n",
        "        e = e/2;\n",
        "        x = x*x;\n",
        "    }\n",
        "\n",
        "    return x*x_r;\n",
        "}\n",
        "\n",
        "// ####################### EXPONENTIATION MODULAIRE ############################\n",
        "\n",
        "chaine mod_pow(chaine a, int e, chaine mod)\n",
        "{\n",
        "    chaine x = a;\n",
        "    chaine x_r = 1;\n",
        " \n",
        "    while(e != 1)\n",
        "    {\n",
        "        if(e % 2)\n",
        "          x_r = x_r*x % mod;\n",
        "        e = e/2;\n",
        "        x = x*x % mod;\n",
        "\n",
        "    }\n",
        "\n",
        "    return x*x_r %mod;\n",
        "}\n",
        "\n",
        "// ####################### HASHER  #############################################\n",
        "\n",
        "chaine hasher(int i, const char* name, int len_name)\n",
        "{\n",
        "    chaine x = i;\n",
        "    for(int j = 0; j < len_name; j++)\n",
        "    {\n",
        "        x = x + x * (chaine)(name[j]) % MODULUS;\n",
        "    }\n",
        "\n",
        "    return mod_pow(x, EXPONENT, MODULUS);\n",
        "}\n",
        "\n",
        "void every_possibilities(chaine *vect, const char* name, int len_name, int NB_POSS)\n",
        "{\n",
        "    for(int i = 0; i < NB_POSS; i++)\n",
        "    {\n",
        "        vect[i] = hasher(i + 13, name, len_name);\n",
        "    }\n",
        "    \n",
        "}\n",
        "\n",
        "// ####################### TEST REMPLISSAGE ####################################\n",
        "void test_every_poss(int NB_POSS)\n",
        "{\n",
        "    chaine v[NB_POSS];\n",
        "    every_possibilities(v, \"bob\", 3, NB_POSS);\n",
        "  \n",
        "    for(int i = 0; i < NB_POSS; i++)\n",
        "    {\n",
        "        printf(\"%d \", v[i] );\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        " \n",
        "    printf(\"%d\\n\", mod_pow(32, 27, 37));\n",
        "}\n",
        "\n",
        "// ####################### CONDITIONS ON THE CHAIN  ############################\n",
        "\n",
        "__global__ void find_the_good_chain(chaine *V, chaine *rep, int taille){\n",
        "  // Fill the response if it founds good chains\n",
        "  int idx = threadIdx.x;\n",
        "\n",
        "  if(idx == 0 or idx >= taille)\n",
        "    return;\n",
        "  if((V[idx] & 0xFFFF000) ==  (V[idx-1] & 0xFFFF000))\n",
        "  {\n",
        "    rep[0] = V[idx];\n",
        "    rep[1] = V[idx-1];\n",
        "  }\n",
        "}\n",
        "\n",
        "// ################################ MAIN #######################################\n",
        "int main()\n",
        "{\n",
        "// ----------------- Initialize data ---------------------------\n",
        "    printf(\"Initialize and sort every possible vectors ... \");\n",
        " \n",
        "    // Generate every possibilities for Alice and Bob\n",
        "    int NB_POSS = 40000;\n",
        "    chaine valice[NB_POSS];\n",
        "    every_possibilities(valice, \"alice\", 5, NB_POSS);\n",
        " \n",
        "    chaine vbob[NB_POSS];\n",
        "    every_possibilities(vbob, \"bob\", 3, NB_POSS);\n",
        "\n",
        "    chaine vres[2*NB_POSS];\n",
        " \n",
        "    // Sort vectors\n",
        "    std::sort(vbob, vbob+NB_POSS);\n",
        "    std::sort(vbob, vbob+NB_POSS);\n",
        "    printf(\"Ok.\\n\\n-------------------\\n\\n\");\n",
        "// -------------------- start Timer -----------------------------\n",
        "    printf(\"Alice and bob arrive ! Merge sort Alice's and Bob's vectors\\n\");\n",
        "    //Initializating the timer:\n",
        "    float TimerV;\n",
        "    cudaEvent_t start, stop;\n",
        "    testCUDA(cudaEventCreate(&start));\n",
        "    testCUDA(cudaEventCreate(&stop));\n",
        "\n",
        "// ----------------- Merge sort 2 vectors ----------------------\n",
        "    testCUDA(cudaEventRecord(start,0));\n",
        "    wrapper_FindPartition(valice, NB_POSS, vbob, NB_POSS, vres);\n",
        "\n",
        "// ------------------- End timer -------------------------------\n",
        "    testCUDA(cudaEventRecord(stop,0));\n",
        "    testCUDA(cudaEventSynchronize(stop));\n",
        "    testCUDA(cudaEventElapsedTime(&TimerV, start, stop));\n",
        "    print_array(vres, 2*NB_POSS);\n",
        "    printf(\"End. Execution time: %f ms\\n \\n\", TimerV);\n",
        "    testCUDA(cudaEventDestroy(start));\n",
        "    testCUDA(cudaEventDestroy(stop));\n",
        " \n",
        "// ----------------- Get the appropriate chain -----------------\n",
        "    printf(\"-------------------n\\nTry to find 2 chains with the same first bits\\n\");\n",
        "    int * V_GPU, * answer, *answer_GPU;\n",
        "    answer = (chaine*)malloc(2*sizeof(chaine));\n",
        "    answer[0] = -13;\n",
        "    answer[1] = -13;\n",
        " \n",
        "    testCUDA(cudaMalloc(&V_GPU, 2*NB_POSS*sizeof(chaine)));\n",
        "    testCUDA(cudaMalloc(&answer_GPU, 2*sizeof(chaine)));\n",
        "    testCUDA(cudaMemcpy(V_GPU, vres, 2*NB_POSS*sizeof(int), cudaMemcpyHostToDevice));\n",
        "    testCUDA(cudaMemcpy(answer_GPU, answer, 2*sizeof(int), cudaMemcpyHostToDevice));\n",
        " \n",
        "    printf(\"Begining of the search... \");\n",
        "    find_the_good_chain<<<1,1024>>>(V_GPU, answer_GPU, 2*NB_POSS);\n",
        "    printf(\"End of the search.\\n\");\n",
        " \n",
        "    testCUDA(cudaMemcpy(answer, answer_GPU, 2*sizeof(chaine), cudaMemcpyDeviceToHost));\n",
        " \n",
        "    testCUDA(cudaFree(V_GPU));\n",
        "    testCUDA(cudaFree(answer_GPU));\n",
        "  \n",
        "    printf(\"2 keys are:\\n\");\n",
        "    std::cout << std::hex << answer[0] << '\\n';\n",
        "    std::cout << std::hex << answer[1] << '\\n';\n",
        "    //printf(\"%d\\n%d\\n\", answer[0] & 0xFFF000, answer[1] & 0xFFF000);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNZnjk1Nr-tv",
        "outputId": "6ade9323-acbf-4ca7-8185-0ea6694b0600"
      },
      "source": [
        "!cd src && make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc -lineinfo main.cu -o main  \n",
            "main.cu(22): warning: variable \"P_x\" was set but never used\n",
            "\n",
            "main.cu(70): warning: variable \"P_x\" was set but never used\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKqtMPPFsDIf",
        "outputId": "255ca0f2-7c03-4379-f1f4-0b23a1ac4abc"
      },
      "source": [
        "!cd src && make run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./main\n",
            "Initialize and sort every possible vectors ... Ok.\n",
            "\n",
            "-------------------\n",
            "\n",
            "Alice and bob arrive ! Merge sort Alice's and Bob's vectors\n",
            "dim: 80000 \n",
            "-13507636 -13507255 -13506814 -13506804 -13506753 -13506653 -13506424 -13506038 -13504435 -13502938  ... 13498008 13498407 13498528 13498888 13500677 13502455 13503343 13503804 13504497 13506701 \n",
            "End. Execution time: 0.760576 ms\n",
            " \n",
            "-------------------n\n",
            "Try to find 2 chains with the same first bits\n",
            "Begining of the search... End of the search.\n",
            "2 keys are:\n",
            "ff36e7fe\n",
            "ff36e707\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
